[["index.html", "Aerial Imagery and Point Cloud Data for Slash Pile Quantification Section 1 Introduction 1.1 Objective 1.2 Data", " Aerial Imagery and Point Cloud Data for Slash Pile Quantification George Woolsey 30 May, 2025 Section 1 Introduction Code in support of “Aerial Imagery and Point Cloud Data for Slash Pile Quantification” 1.1 Objective The objective of this study is to demonstrate the use of aerial point cloud data (SfM) and both RGB and hyperspectral imagery to identify and quanity slash piles. 1.2 Data "],["data-processing.html", "Section 2 Data Processing 2.1 Slash Pile Vector Data 2.2 Load RGB orthomosaic rasters 2.3 Study area imagery 2.4 Point Cloud Data 2.5 Check out one pile", " Section 2 Data Processing Load the standard libraries we use to do work # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(corrplot) # correlation plots # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data library(rgl) # 3d plots library(cloud2trees) # the cloud2trees 2.1 Slash Pile Vector Data # points recorded in field slash_piles_points &lt;- sf::st_read(&quot;D:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles.shp&quot;) %&gt;% dplyr::rename_with(tolower) ## Reading layer `SlashPiles&#39; from data source ## `D:\\PFDP_Data\\PFDP_SlashPiles\\SlashPiles.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 122 features and 8 fields ## Geometry type: POINT ## Dimension: XYZM ## Bounding box: xmin: 1019067 ymin: 4334804 xmax: 1019496 ymax: 4335198 ## z_range: zmin: 0 zmax: 2831.171 ## m_range: mmin: 0 mmax: 1566318000 ## Projected CRS: WGS 84 / UTM zone 12N # polygons annotated using RGB and field-collected points slash_piles_polys &lt;- sf::st_read(&quot;D:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles_Polygons.shp&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate(pile_id = as.factor(pile_idx)) %&gt;% dplyr::select(-pile_idx) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # add point data to polygon sf::st_join(slash_piles_points %&gt;% sf::st_zm()) ## Reading layer `SlashPiles_Polygons&#39; from data source ## `D:\\PFDP_Data\\PFDP_SlashPiles\\SlashPiles_Polygons.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 172 features and 2 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 1018968 ymin: 4334777 xmax: 1019545 ymax: 4335271 ## Projected CRS: WGS 84 / UTM zone 12N what? slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 172 ## Columns: 11 ## $ id &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ pile_id &lt;fct&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ objectid &lt;dbl&gt; 112, 111, 115, 110, 108, 109, 113, 114, 107, 104, NA, 106, N… ## $ comment &lt;chr&gt; &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pi… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ height &lt;dbl&gt; 6.0, 7.0, 7.0, 6.5, 6.0, 6.5, 7.5, 6.0, 6.5, 8.0, 7.5, 6.5, … ## $ diameter &lt;dbl&gt; 10.0, 10.8, 10.0, 9.5, 8.0, 9.5, 10.0, 11.3, 10.0, 9.5, 9.5,… ## $ xcoord &lt;dbl&gt; 1019292, 1019290, 1019330, 1019277, 1019264, 1019270, 101930… ## $ ycoord &lt;dbl&gt; 4335145, 4335158, 4335168, 4335149, 4335111, 4335124, 433512… ## $ refcorner &lt;chr&gt; &quot;R17&quot;, &quot;R18&quot;, &quot;T18&quot;, &quot;Q18&quot;, &quot;Q16&quot;, &quot;Q16&quot;, &quot;R17&quot;, &quot;S17&quot;, &quot;O16… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((1019292 4335147, ..., POLYGON ((1019291 43… where? # mapview::mapview(slash_piles_points, zcol = &quot;comment&quot;, layer.name = &quot;slash piles&quot;) mapview::mapview(slash_piles_polys, zcol = &quot;comment&quot;, layer.name = &quot;slash piles&quot;) 2.2 Load RGB orthomosaic rasters Orthomosaic tif files from the UAS flight imagery that were created in Agisoft Metashape are loaded and stitched together via terra::mosaic. # read list of orthos ortho_list_temp &lt;- list.files( &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , pattern = &quot;*\\\\.(tif|tiff)$&quot;, full.names = T)[] %&gt;% purrr::map(function(x){terra::rast(x)}) ortho_list_temp[[1]] %&gt;% terra::res() # terra::aggregate(20) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ####### ensure the resolution of the rasters matches # terra::res(ortho_list_temp[[1]]) ## function change_res_fn &lt;- function(r, my_res=1, m = &quot;bilinear&quot;){ r2 &lt;- r terra::res(r2) &lt;- my_res r2 &lt;- terra::resample(r, r2, method = m) return(r2) } ## apply the function ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.15)}) # terra::res(ortho_list_temp[[1]]) # ortho_list_temp[[1]] %&gt;% # terra::aggregate(2) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ######## mosaic the raster list ortho_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works ) names(ortho_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;alpha&quot;) # ortho_rast %&gt;% # terra::aggregate(4) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) ortho plot fn ###################################################################################### # function to plot ortho + stand ###################################################################################### ortho_plt_fn = function(stand = las_ctg_dta %&gt;% sf::st_union() %&gt;% sf::st_as_sf(), buffer = 20){ # convert to stars ortho_st &lt;- ortho_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( stand %&gt;% sf::st_buffer(buffer) %&gt;% terra::vect() ) %&gt;% # terra::aggregate(fact = 2, fun = &quot;mean&quot;, na.rm = T) %&gt;% stars::st_as_stars() # convert to rgb ortho_rgb &lt;- stars::st_rgb( ortho_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.005, 0.995) , stretch = &quot;percent&quot; ) # ggplot plt_rgb &lt;- ggplot2::ggplot() + stars::geom_stars(data = ortho_rgb[]) + ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; ) + ggplot2::theme_void() # return(plt_rgb) # combine all plot elements plt_combine = plt_rgb + # geom_sf( # data = stand # , alpha = 0 # , lwd = 1.5 # , color = &quot;gray22&quot; # ) + ggplot2::theme( legend.position = &quot;top&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = ggplot2::margin(0,0,0,0) , legend.text = ggplot2::element_text(size = 8) , legend.title = ggplot2::element_text(size = 8) , legend.key = ggplot2::element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = ggplot2::element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = ggplot2::element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) return(plt_combine) } plot an example slash pile RGB image stand_temp = slash_piles_points %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(diameter)) %&gt;% dplyr::slice(1) %&gt;% sf::st_zm() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # check it with the ortho ortho_plt_fn(stand = stand_temp) ggsave(&quot;../data/pile_rgb.jpeg&quot;, height = 5, width = 5) 2.2.1 Example ratio-based index let’s define a general function for a ratio based (vegetation) index spectral_index_fn &lt;- function(rast, layer1, layer2) { bk &lt;- rast[[layer1]] bi &lt;- rast[[layer2]] vi &lt;- (bk - bi) / (bk + bi) return(vi) } The Green-Red Vegetation Index (GRVI) uses the reflectance of green and red bands to assess vegetation health and identify ground cover types. The formula is GRVI = (green - red) / (green + red). Higher GRVI values indicate healthy vegetation, while negative values suggest soils, and values near zero may indicate water or snow. grvi_rast &lt;- spectral_index_fn(rast = ortho_rast, layer1 = 2, layer2 = 1) names(grvi_rast) &lt;- c(&quot;grvi&quot;) terra::plot(grvi_rast, col = harrypotter::hp(n=100, option = &quot;Slytherin&quot;)) let’s check the GRVI for a pile # check it with the ortho grvi_rast %&gt;% terra::crop(stand_temp %&gt;% sf::st_buffer(20)) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = f), color = NA) + ggplot2::labs(fill=&quot;CHM (m)&quot;) + # harrypotter::scale_fill_hp(&quot;slytherin&quot;) + scale_fill_gradient2(low = &quot;black&quot;, high = &quot;forestgreen&quot;) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 10, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 8, hjust = 0.5, face = &quot;italic&quot;) ) ggsave(&quot;../data/pile_grvi.jpeg&quot;, height = 5, width = 5) 2.3 Study area imagery let’s look at the RGB imagery and pile locations # get the base plot plt_rgb_ortho &lt;- ortho_plt_fn( slash_piles_points %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(50) %&gt;% sf::st_transform(terra::crs(ortho_rast)) ) # add pile locations plt_rgb_ortho + ggplot2::geom_sf( data = slash_piles_points %&gt;% sf::st_transform(terra::crs(ortho_rast)) , ggplot2::aes() # size = diameter , shape = 1 , color = &quot;firebrick&quot; ) + ggplot2::theme(legend.position = &quot;none&quot;) notice these are point measurements of plot locations and the points are not precisely in the center of the pile. notice also there are piles in the imagery that were not measured (e.g. upper-left corner) Update: we created image-annotated pile polygons using the RBG and field-collected pile location data let’s make a panel of plots for each pile p_fn_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , crs = terra::crs(ortho_rast) ) { # scale the buffer based on the largest d &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt ortho_plt_fn(d) + ggplot2::geom_sf(data = d, fill = NA, color = &quot;firebrick&quot;) + ggplot2::labs( subtitle = paste0( tolower(d$comment) , &quot;\\ndiam. = &quot; , scales::comma(d$diameter, accuracy = 0.1) # , &quot;, ht. = &quot; # , scales::comma(d$height, accuracy = 0.1) ) ) } # add pile locations plt_list_rgb &lt;- 1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))) %&gt;% purrr::map(p_fn_temp) plot tiles patchwork::wrap_plots( sample( plt_list_rgb, size = as.integer(nrow(slash_piles_points)/3)) , ncol = 5 ) ggsave(&quot;../data/pile_tiles_rgb.jpeg&quot;, height = 10.5, width = 8) object-based image analysis will require polygon data so that we have sets of pixels (i.e. “objects”) to work with for training our model (nice, we’ll use the image-annotated pile data) another challenge will be training a spectral-based model with the different lighting conditions in the imagery (e.g. piles in shadows or under tree crowns). this different lighting may have also influenced the point cloud generation 2.4 Point Cloud Data Let’s check out the point cloud data we got using UAS-SfM methods # directory with the downloaded .las|.laz files f_temp &lt;- &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # system.file(package = &quot;lidR&quot;, &quot;extdata&quot;, &quot;Megaplot.laz&quot;) # is there data? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;) %&gt;% length() ## [1] 1 # what files are in here? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;)[1] ## [1] &quot;P4Pro_06_17_2021_half_half_optimal_group1_densified_point_cloud.las&quot; what information does lidR read from the catalog? las_ctg &lt;- lidR::readLAScatalog(f_temp) # set the processing options lidR::opt_progress(las_ctg) &lt;- F lidR::opt_filter(las_ctg) &lt;- &quot;-drop_duplicates&quot; lidR::opt_select(las_ctg) &lt;- &quot;xyziRGB&quot; # huh? las_ctg ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## density : 375.4 points/m² ## num. files : 1 that’s a lot of points…can an ordinary laptop handle it? we’ll find out. We’ll plot our point cloud data tiles real quick to orient ourselves las_ctg %&gt;% purrr::pluck(&quot;data&quot;) %&gt;% mapview::mapview(popup = F, layer.name = &quot;point cloud tile&quot;) 2.5 Check out one pile las_temp &lt;- lidR::clip_roi( las_ctg # biggest mechanical , slash_piles_points %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(diameter)) %&gt;% dplyr::slice(1) %&gt;% sf::st_zm() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(lidR::st_crs(las_ctg)) ) what did we get? las_temp@data %&gt;% dplyr::glimpse() ## Rows: 181,282 ## Columns: 7 ## $ X &lt;dbl&gt; 499807.0, 499807.0, 499807.0, 499807.0, 499807.0, 499807.0, … ## $ Y &lt;dbl&gt; 4317975, 4317975, 4317975, 4317975, 4317975, 4317975, 431797… ## $ Z &lt;dbl&gt; 2714.829, 2714.777, 2714.709, 2714.900, 2714.636, 2714.594, … ## $ Intensity &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ R &lt;int&gt; 20224, 16896, 32256, 44288, 21760, 16896, 14592, 35584, 3148… ## $ G &lt;int&gt; 18176, 16640, 34304, 40960, 20480, 14848, 8704, 34048, 34304… ## $ B &lt;int&gt; 16384, 16384, 33280, 36608, 20992, 14336, 7168, 33280, 35072… plot a sample las_temp %&gt;% lidR::plot( color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) make a gif library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_z.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_z&quot;, dir = &quot;../data/&quot;) rgl::close3d() } library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_rgb.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;RGB&quot;, bg = &quot;white&quot;, legend = F ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_rgb&quot;, dir = &quot;../data/&quot;) rgl::close3d() } "],["rgb-classification.html", "Section 3 RGB Classification 3.1 Textural covariates 3.2 Unsupervised classification 3.3 Supervised classification", " Section 3 RGB Classification We’ll use the RGB imagery alone to explore unsupervised and supervised classification algorithms. Ultimately, it is likely we will use an object-based image analysis (OBIA) approach. OBIA is a technique (or a set of techniques) used to analyze digital images that was developed relatively recently in comparison to ‘classic’ pixel-based image approaches (Burnett and Blaschke 2003). We will probably implement the OBIA approach using the SegOptim package presented by Goncalves et al. (2019) In future sections we will explore, integration of spectral data with the 3D point cloud data (i.e. “data fusion”) to test distinguishing the woody material in slash piles from surrounding vegetation or soil. Field-measured slash piles will be used as the ground truth data to perform a confusion matrix-based validation accuracy assessment of the methods. Norton et al. (2022) combined LiDAR and hyperspectral data in a data fusion approach for classification of semi-arid woody cover species and achieved accuracies ranging from 86% to 98% for five woody species We’ll see how far we can get without hyperspectral data since this data is less common 3.1 Textural covariates Rodman et al. (2019) described a method using a series of image processing steps to add supplemental information describing the texture and context surrounding each image pixel in their analysis of forest cover change based only on panchromatic imagery (i.e. “black and white”). These textural covariates may be helpful for identifying slash piles, especially if we only have RGB data. first, we’ll make a single panchromatic band (the mean of red, green, and blue values) from our RGB imagery rgb_to_pan_fn &lt;- function(r, g, b) { pan &lt;- (r + g + b)/3 # replace all 0&#39;s with na pan &lt;- terra::subst(pan, from = 0, to = NA) return(pan) } panchromatic_rast &lt;- rgb_to_pan_fn( ortho_rast[[1]], ortho_rast[[2]], ortho_rast[[3]] ) quick plot terra::plot( panchromatic_rast , col = scales::pal_grey(0, 1)(100) , axes=F, legend = F ) nice, now we’ll make the textural covariates described by Rodman et al. (2019) During these steps, we identified locally dark pixels (indicative of individual trees surrounded by bright grassland) and quantified local standard deviation in brightness using moving windows at multiple scales (sensu Coburn and Roberts 2004; Fig. 3; Appendix S2). We combined these two layers with the original grayscale imagery to create three-band composite imagery (Fig. 3d). The combination of brightness, local minima, and standard deviation emphasizes differences in spectral reflectance that facilitate the separation of different forest structures (e.g., individual trees and dense stands) from non-forested areas. (p. 7) and from Appendix S2 Our first metric identifies pixels that are darker than their surroundings (hereafter “local minima”). To identify local minima, we calculated the mean and standard deviation of pixel brightness at each scale (3-15 pixel windows). A pixel was considered to be darker than its surroundings if its brightness value was lower than the window mean minus two standard deviations. These calculations were made for each window size for each pixel, then summed across all window sizes (thus, local minima values range 0-7, where 7 indicates that a pixel is darker than its surroundings across all moving window sizes; Fig. 3b) For the second metric, we calculated the sum of standard deviation values across all window sizes (Fig. 3c). Standard deviation of pixel brightness is a simple version of local texture that can improve forest classification in high-resolution imagery. While standard deviation is more computationally efficient than many other texture metrics (e.g., entropy based on greylevel co-occurrence matrices), it may still yield comparable performance in classification (Coburn and Roberts 2004). Standard deviation appeared helpful in separating dark forest stands (low brightness, moderate variance) from more homogenous areas (low brightness, low variance; i.e., water bodies, shadows). We combined these three layers (brightness, local minima, and standard deviation) to create a three-band composite image (Fig. 3d) rast_rodmanetal2019_fn &lt;- function( rast, windows_m = c(3,5,7,9,11,13,15), scale_to_1m = T , rast_nm = &quot;panchromatic&quot; ) { rast &lt;- rast[[1]] # scale the windows based on resolution if(scale_to_1m){ windows_m &lt;- round_to_nearest_odd( (1/terra::res(rast)[1])*windows_m ) }else{ windows_m &lt;- round_to_nearest_odd(windows_m) } # means r_means &lt;- windows_m %&gt;% purrr::map(\\(w) terra::focal(x = rast, w = w, fun = &quot;mean&quot;, na.rm = T) ) # r_means[[7]] %&gt;% terra::plot(col = scales::pal_grey(0, 1)(100)) # sds r_sds &lt;- windows_m %&gt;% purrr::map(\\(w) terra::focal(x = rast, w = w, fun = &quot;sd&quot;, na.rm = T) ) # r_sds[[5]] %&gt;% terra::plot(col = scales::pal_grey(0, 1)(100)) # local min local_min_fn &lt;- function(rast, mean, sd) { as.numeric(rast &lt; ( mean-(sd*2) )) } r_local_min &lt;- 1:length(r_means) %&gt;% purrr::map(\\(i) local_min_fn(rast = rast, mean = r_means[[i]], sd = r_sds[[i]]) ) # r_local_min[[5]] %&gt;% terra::plot() # aggregate local min r_local_min_agg &lt;- terra::rast(r_local_min) %&gt;% cumsum() # get the last of the local mins local_minima &lt;- r_local_min_agg[[terra::nlyr(r_local_min_agg)]] # aggregate local sd r_sds_agg &lt;- terra::rast(r_sds) %&gt;% cumsum() # get the last of the local mins local_sd &lt;- r_sds_agg[[terra::nlyr(r_sds_agg)]] # composite composite &lt;- c(rast, local_sd, local_minima) names(composite) &lt;- c(rast_nm, &quot;local_sd&quot;, &quot;local_minima&quot;) # names names(local_minima) &lt;- c(&quot;local_minima&quot;) names(local_sd) &lt;- c(&quot;local_sd&quot;) return(list( local_minima = local_minima , local_sd = local_sd , composite = composite )) } 3.1.1 Raster Texture: Panchromatic implement our rast_rodmanetal2019_fn function rodmanetal2019_panchromatic_rast &lt;- rast_rodmanetal2019_fn( rast = panchromatic_rast , rast_nm = &quot;panchromatic&quot; , scale_to_1m = F ) plot of “local minima” pixels that are darker than their surroundings # plot terra::plot( rodmanetal2019_panchromatic_rast$local_minima , col = scales::pal_grey(0, 1)(8) , axes=F, legend = F ) plot of standard deviation pixel brightness which is a simple version of local texture that can improve forest classification in high-resolution imagery terra::plot( rodmanetal2019_panchromatic_rast$local_sd , col = scales::pal_grey(0, 1)(100) , axes=F, legend = F ) plot of these combined panchromatic, local minima, and standard deviation images were merged to create a three-band composite which can be segmented to identify areas of relatively homogeneous brightness, contrast, and variance terra::plotRGB( rodmanetal2019_panchromatic_rast$composite # , scale = c(255,7,520) , stretch = &quot;hist&quot;, colNA = &quot;transparent&quot; ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) 3.1.2 Raster Texture: GRVI implement our rast_rodmanetal2019_fn function rodmanetal2019_grvi_rast &lt;- rast_rodmanetal2019_fn( rast = grvi_rast , rast_nm = &quot;grvi&quot; , scale_to_1m = F ) plot of these combined GRVI terra::plotRGB( rodmanetal2019_grvi_rast$composite # , scale = c(255,7,520) , stretch = &quot;hist&quot;, colNA = &quot;transparent&quot; ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) 3.1.3 Plot textural rasters let’s look at these textural rasters for some of the piles p_fn_temp &lt;- function( rn , df = slash_piles_polys , composite_rast = rodmanetal2019_grvi_rast$composite , crs = terra::crs(ortho_rast) , my_title = &quot;&quot; ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt classifier # convert to stars comp_st &lt;- composite_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(20) %&gt;% terra::vect() ) %&gt;% # terra::aggregate(fact = 2, fun = &quot;mean&quot;, na.rm = T) %&gt;% stars::st_as_stars() # convert to rgb comp_rgb &lt;- stars::st_rgb( comp_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.002, 0.998) , stretch = &quot;percent&quot; ) # ggplot comp_temp &lt;- ggplot2::ggplot() + stars::geom_stars(data = comp_rgb[]) + ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 0.3) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , subtitle = my_title ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) plt_temp &lt;- comp_temp return(list(&quot;plt&quot;=plt_temp,&quot;d&quot;=d_temp)) } # combine 3 plt_combine_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , composite_rast1 = rodmanetal2019_panchromatic_rast$composite , title1 = &quot;panchromatic composite&quot; , composite_rast2 = rodmanetal2019_grvi_rast$composite , title2 = &quot;GRVI composite&quot; , crs = terra::crs(ortho_rast) ) { # composite 1 ans1 &lt;- p_fn_temp( rn = rn , df = df , composite_rast = composite_rast1 , my_title = title1 , crs = crs ) # composite 2 ans2 &lt;- p_fn_temp( rn = rn , df = df , composite_rast = composite_rast2 , my_title = title2 , crs = crs ) # plt rgb rgb_temp &lt;- ortho_plt_fn(ans1$d) + ggplot2::geom_sf(data = ans1$d, fill = NA, color = &quot;white&quot;, lwd = 0.3) # combine r &lt;- ans1$plt + ans2$plt + rgb_temp return(r) } # add pile locations plt_list_grvi_comp &lt;- sample(1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))),10) %&gt;% purrr::map(plt_combine_temp) # plt_list_grvi_comp[[2]] combine the plots for a few piles patchwork::wrap_plots( plt_list_grvi_comp , ncol = 1 ) ggplot2::ggsave(&quot;../data/pile_tiles_texture.jpeg&quot;, height = 10.5, width = 5) 3.2 Unsupervised classification Unsupervised image classification could be used to identify slash piles by grouping pixels with similar spectral characteristics. We’ll call any method that implements classification at the pixel level like the unsupervised classification approach tested here “pixel-based image analysis” versus to OBIA. Unsupervised image classification uses algorithms like K-means to find natural clusters within spectral data and can use other inputs like elevation or spectral indices. This method operates without requiring pre-defined training data, making it useful when field data is limited. The output assigns each pixel to a class, which the user then interprets to potentially identify slash piles based on their distinct spectral signatures and elevated height. While effective for initial classification and pattern recognition, unsupervised methods can produce numerous classes that require manual interpretation and may be less accurate than supervised approaches without ground truth data. let’s test it out and see what we get first, we’ll convert our rasters to a data frame #rename composites names(rodmanetal2019_panchromatic_rast$composite) &lt;- c( &quot;panchromatic&quot;, &quot;panchromatic_local_sd&quot;, &quot;panchromatic_local_minima&quot; ) names(rodmanetal2019_grvi_rast$composite) &lt;- c( &quot;grvi&quot;, &quot;grvi_local_sd&quot;, &quot;grvi_local_minima&quot; ) # raster stack pred_rast &lt;- c( terra::subset(ortho_rast, c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)) , rodmanetal2019_panchromatic_rast$composite , rodmanetal2019_grvi_rast$composite ) check out correlations between covariates # investigate correlation among environmental covariates pred_rast %&gt;% terra::pairs( maxcells = min(7777, terra::ncell(pred_rast)*.01) ) the panchromatic band itself doesn’t add much new information, let’s remove it and generate a data frame for training kmeans clustering # remove correlated layers pred_rast &lt;- terra::subset( pred_rast , subset = c(&quot;panchromatic&quot;) , negate = T ) # combine rasters as data frame pred_df &lt;- terra::as.data.frame( pred_rast , xy = T , cell = T ) %&gt;% dplyr::mutate( dplyr::across( .cols = c(red,green,blue) , .fns = ~ ifelse(.x==0,NA,.x) ) ) # what is this data? pred_df %&gt;% dplyr::slice_sample(n=100) %&gt;% dplyr::glimpse() ## Rows: 100 ## Columns: 11 ## $ cell &lt;dbl&gt; 1732458, 9273634, 1693316, 10236607, 6789055… ## $ x &lt;dbl&gt; 499679.4, 499456.2, 499953.3, 499831.3, 4995… ## $ y &lt;dbl&gt; 4318082, 4317834, 4318084, 4317802, 4317916,… ## $ red &lt;dbl&gt; 97.70557, 31.03595, NA, 98.23176, 91.81036, … ## $ green &lt;dbl&gt; 112.66428, 34.53605, NA, 100.26696, 96.95100… ## $ blue &lt;dbl&gt; 64.07671, 39.03930, NA, 91.79925, 99.08756, … ## $ panchromatic_local_sd &lt;dbl&gt; 189.82342, 106.98445, NA, 228.27211, 288.939… ## $ panchromatic_local_minima &lt;dbl&gt; 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ grvi &lt;dbl&gt; 0.071106755, 0.053377894, NA, 0.010252973, 0… ## $ grvi_local_sd &lt;dbl&gt; 0.14033654, 0.18129285, NA, 0.29922352, 0.17… ## $ grvi_local_minima &lt;dbl&gt; 0, 0, NA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… perform kmeans clustering set.seed(111) # Create 6 clusters, allow 500 iterations, start with 5 random sets using &quot;Lloyd&quot; kmncluster &lt;- stats::kmeans( pred_df %&gt;% dplyr::select(-c(cell,x,y)) %&gt;% # we can&#39;t have NA values in kmeans dplyr::mutate( dplyr::across( .cols = dplyr::everything() , .fns = ~ as.numeric(ifelse(is.na(.x),-99,.x)) ) ) , centers=6 , iter.max = 500 , nstart = 5 , algorithm=&quot;Lloyd&quot; ) # kmeans returns an object of class kmeans str(kmncluster) ## List of 9 ## $ cluster : Named int [1:16236984] 4 4 4 4 4 4 4 4 4 4 ... ## ..- attr(*, &quot;names&quot;)= chr [1:16236984] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ centers : num [1:6, 1:8] 165.8 29.7 110.6 -99 53.2 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. ..$ : chr [1:8] &quot;red&quot; &quot;green&quot; &quot;blue&quot; &quot;panchromatic_local_sd&quot; ... ## $ totss : num 3.22e+11 ## $ withinss : num [1:6] 1.29e+10 6.39e+09 7.97e+09 4.91e+08 8.79e+09 ... ## $ tot.withinss: num 4.45e+10 ## $ betweenss : num 2.77e+11 ## $ size : int [1:6] 5327066 2385838 3892966 583431 2126720 1920963 ## $ iter : int 64 ## $ ifault : NULL ## - attr(*, &quot;class&quot;)= chr &quot;kmeans&quot; put the kmeans clusters into a raster # make a blank raster kmeans_cluster_rast &lt;- terra::rast(ortho_rast, nlyr=1) # fill the raster kmeans_cluster_rast[pred_df$cell] &lt;- kmncluster$cluster # what? kmeans_cluster_rast ## class : SpatRaster ## dimensions : 3567, 4552, 1 (nrow, ncol, nlyr) ## resolution : 0.15, 0.15 (x, y) ## extent : 499274.8, 499957.6, 4317604, 4318139 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## name : lyr1 ## min value : 1 ## max value : 6 there should be at most 6 clusters terra::freq(kmeans_cluster_rast) ## layer value count ## 1 1 1 5327066 ## 2 1 2 2385838 ## 3 1 3 3892966 ## 4 1 4 583431 ## 5 1 5 2126720 ## 6 1 6 1920963 plot the kmeans unsupervised classfication result terra::plot( kmeans_cluster_rast , col = viridis::turbo(n=6) , axes=F, legend = F ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) neat, let’s see if the piles are classified by making a custom function to plot the classified raster and RGB side-by-side p_fn_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , cluster_rast = kmeans_cluster_rast , crs = terra::crs(ortho_rast) ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt rgb_temp &lt;- ortho_plt_fn(d_temp) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 1) # plt classifier class_temp &lt;- ggplot2::ggplot() + ggplot2::geom_tile( data = cluster_rast %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(20) %&gt;% terra::vect() ) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , ggplot2::aes(x=x,y=y,fill=as.factor(f)) ) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 1) + ggplot2::scale_fill_manual( values = c( &quot;1&quot; = viridis::turbo(n=6)[1] , &quot;2&quot; = viridis::turbo(n=6)[2] , &quot;3&quot; = viridis::turbo(n=6)[3] , &quot;4&quot; = viridis::turbo(n=6)[4] , &quot;5&quot; = viridis::turbo(n=6)[5] , &quot;6&quot; = viridis::turbo(n=6)[6] # , &quot;7&quot; = viridis::turbo(n=10)[7] # , &quot;8&quot; = viridis::turbo(n=10)[8] # , &quot;9&quot; = viridis::turbo(n=10)[9] # , &quot;10&quot; = viridis::turbo(n=10)[10] ) , na.value = &quot;transparent&quot; ) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , fill = &quot;&quot; ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;left&quot; # c(0.5,1) , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 6) , legend.title = element_text(size = 6) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) plt_temp &lt;- class_temp+rgb_temp return(plt_temp) } # add pile locations plt_list_kmeans &lt;- sample(1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))),10) %&gt;% purrr::map(p_fn_temp) combine the plots for a few piles patchwork::wrap_plots( plt_list_kmeans , ncol = 2 , guides = &quot;collect&quot; ) ggplot2::ggsave(&quot;../data/pile_tiles_kmeans6.jpeg&quot;, height = 10.5, width = 8) there is no discernible pattern between the kmeans classes and the slash piles because the lighting and conditions around the piles are not consistent. this result also highlights the challenges we’ll likely face with pixel-based classification methods 3.3 Supervised classification we’ll start with a pixel-based classification using the image-annotated pile polygons to train a classification model first, let’s set aside some piles for use in validation set.seed(333) # 20% will be used for validation slash_piles_polys &lt;- slash_piles_polys %&gt;% dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(!is.na(comment)) %&gt;% dplyr::distinct(pile_id) %&gt;% dplyr::slice_sample(prop = 0.2) %&gt;% dplyr::mutate(is_training = F) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate(is_training = dplyr::coalesce(is_training, T)) slash_piles_points &lt;- slash_piles_points %&gt;% dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(objectid, is_training) , by = &quot;objectid&quot; ) # slash_piles_points %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(is_training) first, we’ll generate a set of sample points to extract raster values from to build our training data with covariates training_points &lt;- dplyr::bind_rows( # sample only from non-pile parts of the raster terra::mask( grvi_rast , slash_piles_polys %&gt;% # use ALL piles (image-annotated and field-collected) sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , inverse = T ) %&gt;% terra::spatSample(size = 5000, na.rm = T, xy = T) %&gt;% sf::st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;), crs = terra::crs(grvi_rast)) %&gt;% dplyr::mutate( is_pile = 0 ) %&gt;% dplyr::select(is_pile) # sample points within piles , slash_piles_polys %&gt;% dplyr::filter( is_training ) %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() %&gt;% terra::spatSample(size = 1000) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate( is_pile = 1 ) %&gt;% dplyr::select(is_pile) ) %&gt;% dplyr::mutate( id = dplyr::row_number() , is_pile = as.factor(is_pile) , x = sf::st_coordinates(.)[,1] , y = sf::st_coordinates(.)[,2] ) ####### validation points since we&#39;ll validate at the pixel level validation_points &lt;- dplyr::bind_rows( # sample only from non-pile parts of the raster terra::mask( grvi_rast , slash_piles_polys %&gt;% # use ALL piles (image-annotated and field-collected) sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , inverse = T ) %&gt;% # mask the training points as well terra::mask( training_points %&gt;% terra::vect() , inverse = T ) %&gt;% terra::spatSample(size = 5000, na.rm = T, xy = T) %&gt;% sf::st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;), crs = terra::crs(grvi_rast)) %&gt;% dplyr::mutate( is_pile = 0 ) %&gt;% dplyr::select(is_pile) # sample points within piles , slash_piles_polys %&gt;% dplyr::filter( !is_training ) %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() %&gt;% terra::spatSample(size = 1000) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate( is_pile = 1 ) %&gt;% dplyr::select(is_pile) ) %&gt;% dplyr::mutate( id = dplyr::row_number() , is_pile = as.factor(is_pile) , x = sf::st_coordinates(.)[,1] , y = sf::st_coordinates(.)[,2] ) plot our RGB with training piles (white), validation piles(black), pile sample points (red), and non-pile sample points (blue) # let&#39;s check this out terra::plotRGB(ortho_rast, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) terra::plot( slash_piles_polys %&gt;% dplyr::filter(is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% dplyr::filter(!is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot(training_points %&gt;% dplyr::filter(is_pile==1) %&gt;% terra::vect(), col = &quot;red&quot;, cex = 0.5, add = T) terra::plot(training_points %&gt;% dplyr::filter(is_pile==0) %&gt;% terra::vect(), col = &quot;blue&quot;, cex = 0.5, add = T) extract the raster cell values from each layer in our RGB-based raster data, these values will be the predictor variables ############################# #extract covariate data at point locations ############################# training_dta &lt;- terra::extract( pred_rast , training_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::bind_cols( training_points %&gt;% dplyr::select(id,is_pile,x,y) ) %&gt;% ## make sure no data is missing dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.x))) # ## square continuous vars? # dplyr::mutate(dplyr::across( # .cols = dplyr::where(is.numeric) &amp; !c(id, is_pile, x, y) &amp; !tidyselect::ends_with(&quot;local_minima&quot;) # , .fns = list(sq) # , .names = &quot;{.col}_sq&quot; # )) ##### and validation data to perform accuracy assesment at the pixel level validation_dta &lt;- terra::extract( pred_rast , validation_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::bind_cols( validation_points %&gt;% dplyr::select(id,is_pile,x,y) ) %&gt;% ## make sure no data is missing dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.x))) # ## square continuous vars? # dplyr::mutate(dplyr::across( # .cols = dplyr::where(is.numeric) &amp; !c(id, is_pile, x, y) &amp; !tidyselect::ends_with(&quot;local_minima&quot;) # , .fns = list(sq) # , .names = &quot;{.col}_sq&quot; # )) compare training and validation data to ensure that they are similar (i.e. we drew a big enough sample) dplyr::bind_rows( training_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate(dta_set = &quot;Training&quot;) , validation_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate(dta_set = &quot;Validation&quot;) ) %&gt;% dplyr::select(-c(geometry,dplyr::ends_with(&quot;_sq&quot;))) %&gt;% dplyr::mutate_if(is.factor, as.numeric) %&gt;% tidyr::pivot_longer( cols = -c(id, is_pile, dta_set) , names_to = &quot;covariate&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate(covariate = stringr::str_replace_all(covariate,&quot;_&quot;, &quot; &quot;)) %&gt;% ggplot(mapping = aes(x = value, color = dta_set, fill = dta_set, group = dta_set)) + geom_density(alpha=0.6) + facet_wrap( facets = vars(covariate), scales = &quot;free&quot; , labeller = label_wrap_gen(width = 25, multi_line = TRUE) ) + scale_color_viridis_d(option = &quot;cividis&quot;) + scale_fill_viridis_d(option = &quot;cividis&quot;) + labs( title = &quot;Distribution of Model Covariates&quot; , subtitle = paste0( &quot;by Training (n=&quot; , nrow(training_dta) %&gt;% scales::comma(accuracy = 1) , &quot;) and Validation (n=&quot; , nrow(validation_dta) %&gt;% scales::comma(accuracy = 1) , &quot;) data&quot; ) ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.title = element_blank() , plot.title = element_text(size = 10) , plot.subtitle = element_text(size = 9) , axis.title = element_text(size = 7) , axis.text = element_text(size = 6) ) + guides(color = guide_legend(override.aes = list(size = 5))) we’ll use a random forest model to predict raster values # Tune on the full data if below threshold tune_result_temp &lt;- randomForest::tuneRF( y = training_dta$is_pile , x = training_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(id,is_pile,geometry)) , ntreeTry = 500 , stepFactor = 1 , improve = 0.03 , plot = F , trace = F ) # Extract the optimal mtry value optimal_mtry_temp &lt;- tune_result_temp %&gt;% dplyr::as_tibble() %&gt;% dplyr::filter(OOBError==min(OOBError)) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::pull(mtry) %&gt;% as.numeric() # pass to random forest model mod_rf &lt;- randomForest::randomForest( y = training_dta$is_pile , x = training_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(id,is_pile,geometry)) , mtry = optimal_mtry_temp , na.action = na.omit , ntree = 500 ) random forest variable importance plot #variable importance plot randomForest::varImpPlot(mod_rf) predict raster values # x,y rasters y_rast_temp &lt;- terra::init(pred_rast[[1]], &quot;y&quot;) names(y_rast_temp) &lt;- &quot;y&quot; x_rast_temp &lt;- terra::init(pred_rast[[1]], &quot;x&quot;) names(x_rast_temp) &lt;- &quot;x&quot; # predict rf_pred_rast &lt;- terra::predict( object = c( pred_rast , x_rast_temp, y_rast_temp ) , model = mod_rf , na.rm = T # , type = &quot;prob&quot; ) terra::coltab(rf_pred_rast) &lt;- data.frame(value=1:2, col=c(&quot;gray&quot;, &quot;khaki&quot;)) levels(rf_pred_rast) &lt;- data.frame(value=1:2, col=c(&quot;non-pile&quot;, &quot;pile&quot;)) plot pixel-level predictions #plot terra::plot(rf_pred_rast) terra::plot( slash_piles_polys %&gt;% dplyr::filter(is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% dplyr::filter(!is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) evaluate model performance based on the Area under the Receiver Operating Characteristic (ROC) Curve (AUC) criterion (an AUC value of 0.5 can be interpreted as the model performing no better than a random prediction). Higher AUC values indicate that the model is better at predicting “absence” classes as “absence” (true negative) and “presence” classes as “presence” (true positive). validation_dta &lt;- validation_dta %&gt;% dplyr::bind_cols( terra::extract( rf_pred_rast , validation_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::rename(is_pile_predicted=1) ) PresenceAbsence::auc.roc.plot( validation_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(id, is_pile, is_pile_predicted) %&gt;% dplyr::mutate(dplyr::across(tidyselect::starts_with(&quot;is_pile&quot;), ~ as.numeric(.x)-1 )) , main = &quot;Random Forest&quot; ) now lets check the confusion matrix of the pixel-based approach confusion_matrix_temp &lt;- validation_dta %&gt;% dplyr::mutate(dplyr::across(tidyselect::starts_with(&quot;is_pile&quot;), ~ as.numeric(.x)-1 )) %&gt;% dplyr::rename( presence = is_pile , estimate = is_pile_predicted ) %&gt;% dplyr::count(presence,estimate) %&gt;% dplyr::mutate( is_false = as.factor(ifelse(presence!=estimate,1,0)) , presence_fact = factor(presence,levels = 0:1,labels = c(&quot;Observed Absent&quot;, &quot;Observed Present&quot;)) , estimate_fact = factor(estimate,levels = 0:1,labels = c(&quot;Predicted Absent&quot;, &quot;Predicted Present&quot;)) , pct = n/sum(n) ) # first function takes df with cols tp_n, fp_n, and fn_n to calculate rate confusion_matrix_scores_fn &lt;- function(df) { df %&gt;% dplyr::mutate( omission_rate = dplyr::case_when( (tp_n+fn_n) == 0 ~ as.numeric(NA) , T ~ fn_n/(tp_n+fn_n) ) # False Negative Rate or Miss Rate , commission_rate = dplyr::case_when( (tp_n+fp_n) == 0 ~ as.numeric(NA) , T ~ fp_n/(tp_n+fp_n) ) # False Positive Rate , precision = dplyr::case_when( (tp_n+fp_n) == 0 ~ as.numeric(NA) , T ~ tp_n/(tp_n+fp_n) ) , recall = dplyr::case_when( (tp_n+fn_n) == 0 ~ as.numeric(NA) , T ~ tp_n/(tp_n+fn_n) ) , f_score = dplyr::case_when( is.na(precision) | is.na(recall) ~ as.numeric(NA) , (precision+recall) == 0 ~ 0 , T ~ 2 * ( (precision*recall)/(precision+recall) ) ) ) } confusion_matrix_scores_temp &lt;- confusion_matrix_scores_fn( dplyr::tibble( tp_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==1 &amp; estimate == 1) %&gt;% dplyr::pull(n) , fn_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==1 &amp; estimate == 0) %&gt;% dplyr::pull(n) , fp_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==0 &amp; estimate == 1) %&gt;% dplyr::pull(n) ) ) # plot ggplot(data = confusion_matrix_temp, mapping = aes(y = estimate_fact, x = presence_fact)) + geom_tile(aes(fill = is_false), color = &quot;white&quot;,alpha=0.8) + geom_text(aes(label = scales::comma(n,accuracy=1)), vjust = 1,size = 8) + geom_text(aes(label = scales::percent(pct,accuracy=0.1)), vjust = 3.5, size=5) + scale_fill_manual(values= c(&quot;turquoise&quot;,&quot;tomato2&quot;)) + scale_x_discrete(position = &quot;top&quot;) + labs( y = &quot;Predicted&quot; , x = &quot;Observed&quot; , subtitle = paste0( &quot;True positive rate (recall) = &quot; , confusion_matrix_scores_temp$recall %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nPrecision (PPV) = &quot; , confusion_matrix_scores_temp$precision %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nF1-score = &quot; , confusion_matrix_scores_temp$f_score %&gt;% scales::percent(accuracy = 0.1) ) ) + theme_light() + theme( legend.position = &quot;none&quot; , panel.grid = element_blank() , plot.title = element_text(size = 9) , plot.subtitle = element_text(size = 9) ) that’s not very good as we could tell from the prediction map "],["point-cloud-classification.html", "Section 4 Point Cloud Classification 4.1 Process Raw Point Cloud", " Section 4 Point Cloud Classification We’ll use the point cloud data alone (to begin with) to attempt to classify slash piles without additional spectral information. We’ll use the cloud2trees package to perform all preprocessing of point cloud data which includes: ground classification and noise removal raster data (DTM and CHM) generation point cloud height normalization All of this can be accomplished using the cloud2raster() function. After generating these products from the raw point cloud we’ll perform object segmentation to attempt to detect round, conical objects like slash piles from: 1) the normalized point cloud directly; 2) the CHM which we’ll generate by setting the minimum height to zero to effectively create a digital surface model (DSM). To attempt to detect slash piles directly from the point cloud we can use a clustering algorithm such as DBSCAN (Density-Based Spatial Clustering of Applications with Noise) which identifies clusters based on point density, making it effective for detecting clusters of arbitrary shapes and sizes. It does not require the number of clusters to be specified beforehand. Insert something from TLS paper that used DBSCAN in semi-automated way….xxxxx. After segmenting the point cloud using DBSCAN, random forest can be used as a classifier (i.e. classification step) to distinguish slash piles from other objects based on their extracted geometric features. The general workflow is: for each point in the normalized non-ground point cloud, compute a suite of relevant geometric features within a defined local neighborhood radius using lidR::point_metrics() calculate features derived from PCA, such as linearity, planarity, sphericity, and surface variation. Also, compute curvature (mean, Gaussian) and roughness perform object segmentation/clustering to group points belonging to individual objects using DBSCAN which can identify dense clusters without requiring a predefined number of objects classify the segmented objects (clusters) as “slash pile” or “non-slash pile” based on their extracted features (e.g., sphericity, roughness, height, volume) with a random forest classifier using a manually annotated subset of segmented objects merge small, adjacent segments that likely belong to a single slash pile based on proximity and connectivity perform a confusion matrix-based evaluation on the results To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation (potentially without “seed” points) in a bottom-up approach. Insert something from paper about bottom-up approach that uses a CHM “slice” near the ground…xxxxx. For slash piles, which are often irregular and may not have a distinct “treetop” equivalent, CHM-based methods might be less directly applicable unless the piles present a very clear, isolated conical or rounded form. Could use expected morphology of the slash piles (e.g. maximum height) based on prior research. 4.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data if(!dir.exists(&quot;../data/point_cloud_processing_delivery&quot;)){ cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = &quot;../data&quot; , input_las_dir = &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; , max_ctg_pts = 9e+07 , accuracy_level = 3 , keep_intrmdt = T , dtm_res_m = 0.5 , chm_res_m = 0.2 , min_height = 0 # effectively generates a DSM based on non-ground points ) }else{ dtm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery/dtm_0.5m.tif&quot;) chm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery/chm_0.2m.tif&quot;) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM and CHM "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
