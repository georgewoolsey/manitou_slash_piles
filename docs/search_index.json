[["index.html", "Aerial Imagery and Point Cloud Data for Slash Pile Quantification Section 1 Introduction 1.1 Objective 1.2 Data", " Aerial Imagery and Point Cloud Data for Slash Pile Quantification George Woolsey 05 June, 2025 Section 1 Introduction Code in support of “Aerial Imagery and Point Cloud Data for Slash Pile Quantification” 1.1 Objective The objective of this study is to demonstrate the use of aerial point cloud data (SfM) and both RGB and hyperspectral imagery to identify and quanity slash piles. 1.2 Data "],["data-processing.html", "Section 2 Data Processing 2.1 Slash Pile Vector Data 2.2 Load RGB orthomosaic rasters 2.3 Study area imagery 2.4 Point Cloud Data 2.5 Check out one pile", " Section 2 Data Processing Load the standard libraries we use to do work # bread-and-butter library(tidyverse) # the tidyverse library(viridis) # viridis colors library(harrypotter) # hp colors library(RColorBrewer) # brewer colors library(scales) # work with number and plot scales library(latex2exp) # visualization library(mapview) # interactive html maps library(kableExtra) # tables library(patchwork) # combine plots library(corrplot) # correlation plots # spatial analysis library(terra) # raster library(sf) # simple features library(lidR) # lidar data library(rgl) # 3d plots library(cloud2trees) # the cloud2trees library(glcm) # textures of rasters 2.1 Slash Pile Vector Data # points recorded in field slash_piles_points &lt;- sf::st_read(&quot;D:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles.shp&quot;) %&gt;% dplyr::rename_with(tolower) ## Reading layer `SlashPiles&#39; from data source ## `D:\\PFDP_Data\\PFDP_SlashPiles\\SlashPiles.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 122 features and 8 fields ## Geometry type: POINT ## Dimension: XYZM ## Bounding box: xmin: 1019067 ymin: 4334804 xmax: 1019496 ymax: 4335198 ## z_range: zmin: 0 zmax: 2831.171 ## m_range: mmin: 0 mmax: 1566318000 ## Projected CRS: WGS 84 / UTM zone 12N # polygons annotated using RGB and field-collected points slash_piles_polys &lt;- sf::st_read(&quot;D:\\\\PFDP_Data\\\\PFDP_SlashPiles\\\\SlashPiles_Polygons.shp&quot;) %&gt;% dplyr::rename_with(tolower) %&gt;% dplyr::mutate(pile_id = as.factor(pile_idx)) %&gt;% dplyr::select(-pile_idx) %&gt;% sf::st_make_valid() %&gt;% dplyr::filter(sf::st_is_valid(.)) %&gt;% # add point data to polygon sf::st_join(slash_piles_points %&gt;% sf::st_zm()) ## Reading layer `SlashPiles_Polygons&#39; from data source ## `D:\\PFDP_Data\\PFDP_SlashPiles\\SlashPiles_Polygons.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 172 features and 2 fields ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 1018968 ymin: 4334777 xmax: 1019545 ymax: 4335271 ## Projected CRS: WGS 84 / UTM zone 12N what? slash_piles_polys %&gt;% dplyr::glimpse() ## Rows: 172 ## Columns: 11 ## $ id &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ pile_id &lt;fct&gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17… ## $ objectid &lt;dbl&gt; 112, 111, 115, 110, 108, 109, 113, 114, 107, 104, NA, 106, N… ## $ comment &lt;chr&gt; &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pile&quot;, &quot;Hand Pi… ## $ comment2 &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, … ## $ height &lt;dbl&gt; 6.0, 7.0, 7.0, 6.5, 6.0, 6.5, 7.5, 6.0, 6.5, 8.0, 7.5, 6.5, … ## $ diameter &lt;dbl&gt; 10.0, 10.8, 10.0, 9.5, 8.0, 9.5, 10.0, 11.3, 10.0, 9.5, 9.5,… ## $ xcoord &lt;dbl&gt; 1019292, 1019290, 1019330, 1019277, 1019264, 1019270, 101930… ## $ ycoord &lt;dbl&gt; 4335145, 4335158, 4335168, 4335149, 4335111, 4335124, 433512… ## $ refcorner &lt;chr&gt; &quot;R17&quot;, &quot;R18&quot;, &quot;T18&quot;, &quot;Q18&quot;, &quot;Q16&quot;, &quot;Q16&quot;, &quot;R17&quot;, &quot;S17&quot;, &quot;O16… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((1019292 4335147, ..., POLYGON ((1019291 43… where? # mapview::mapview(slash_piles_points, zcol = &quot;comment&quot;, layer.name = &quot;slash piles&quot;) mapview::mapview(slash_piles_polys, zcol = &quot;comment&quot;, layer.name = &quot;slash piles&quot;) 2.2 Load RGB orthomosaic rasters Orthomosaic tif files from the UAS flight imagery that were created in Agisoft Metashape are loaded and stitched together via terra::mosaic. # read list of orthos ortho_list_temp &lt;- list.files( &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\3_dsm_ortho\\\\2_mosaic&quot; , pattern = &quot;*\\\\.(tif|tiff)$&quot;, full.names = T)[] %&gt;% purrr::map(function(x){terra::rast(x)}) ortho_list_temp[[1]] %&gt;% terra::res() # terra::aggregate(20) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ####### ensure the resolution of the rasters matches # terra::res(ortho_list_temp[[1]]) ## function change_res_fn &lt;- function(r, my_res=1, m = &quot;bilinear&quot;){ r2 &lt;- r terra::res(r2) &lt;- my_res r2 &lt;- terra::resample(r, r2, method = m) return(r2) } ## apply the function ortho_list_temp &lt;- 1:length(ortho_list_temp) %&gt;% purrr::map(function(x){change_res_fn(ortho_list_temp[[x]], my_res=0.25)}) # terra::res(ortho_list_temp[[1]]) # ortho_list_temp[[1]] %&gt;% # terra::aggregate(2) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;hist&quot;, colNA = &quot;transparent&quot;) ######## mosaic the raster list ortho_rast &lt;- terra::mosaic( terra::sprc(ortho_list_temp) , fun = &quot;min&quot; # min only thing that works ) names(ortho_rast) &lt;- c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;alpha&quot;) # ortho_rast %&gt;% # terra::aggregate(4) %&gt;% # terra::plotRGB(r = 1, g = 2, b = 3, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) ortho plot fn ###################################################################################### # function to plot ortho + stand ###################################################################################### ortho_plt_fn = function(stand = las_ctg_dta %&gt;% sf::st_union() %&gt;% sf::st_as_sf(), buffer = 20){ # convert to stars ortho_st &lt;- ortho_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( stand %&gt;% sf::st_buffer(buffer) %&gt;% terra::vect() ) %&gt;% # terra::aggregate(fact = 2, fun = &quot;mean&quot;, na.rm = T) %&gt;% stars::st_as_stars() # convert to rgb ortho_rgb &lt;- stars::st_rgb( ortho_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.005, 0.995) , stretch = &quot;percent&quot; ) # ggplot plt_rgb &lt;- ggplot2::ggplot() + stars::geom_stars(data = ortho_rgb[]) + ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; ) + ggplot2::theme_void() # return(plt_rgb) # combine all plot elements plt_combine = plt_rgb + # geom_sf( # data = stand # , alpha = 0 # , lwd = 1.5 # , color = &quot;gray22&quot; # ) + ggplot2::theme( legend.position = &quot;top&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = ggplot2::margin(0,0,0,0) , legend.text = ggplot2::element_text(size = 8) , legend.title = ggplot2::element_text(size = 8) , legend.key = ggplot2::element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = ggplot2::element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = ggplot2::element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) return(plt_combine) } plot an example slash pile RGB image stand_temp = slash_piles_points %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(diameter)) %&gt;% dplyr::slice(1) %&gt;% sf::st_zm() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(terra::crs(ortho_rast)) # check it with the ortho ortho_plt_fn(stand = stand_temp) ggsave(&quot;../data/pile_rgb.jpeg&quot;, height = 5, width = 5) 2.2.1 Example ratio-based index let’s define a general function for a ratio based (vegetation) index spectral_index_fn &lt;- function(rast, layer1, layer2) { bk &lt;- rast[[layer1]] bi &lt;- rast[[layer2]] vi &lt;- (bk - bi) / (bk + bi) return(vi) } The Green-Red Vegetation Index (GRVI) uses the reflectance of green and red bands to assess vegetation health and identify ground cover types. The formula is GRVI = (green - red) / (green + red). Higher GRVI values indicate healthy vegetation, while negative values suggest soils, and values near zero may indicate water or snow. grvi_rast &lt;- spectral_index_fn(rast = ortho_rast, layer1 = 2, layer2 = 1) names(grvi_rast) &lt;- c(&quot;grvi&quot;) terra::plot(grvi_rast, col = harrypotter::hp(n=100, option = &quot;Slytherin&quot;)) let’s check the GRVI for a pile # check it with the ortho grvi_rast %&gt;% terra::crop(stand_temp %&gt;% sf::st_buffer(20)) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) %&gt;% ggplot2::ggplot() + ggplot2::geom_tile(ggplot2::aes(x=x,y=y,fill = f), color = NA) + ggplot2::labs(fill=&quot;CHM (m)&quot;) + # harrypotter::scale_fill_hp(&quot;slytherin&quot;) + scale_fill_gradient2(low = &quot;black&quot;, high = &quot;forestgreen&quot;) + scale_x_continuous(expand = c(0, 0)) + scale_y_continuous(expand = c(0, 0)) + ggplot2::theme_void() + theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 10, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 8, hjust = 0.5, face = &quot;italic&quot;) ) ggsave(&quot;../data/pile_grvi.jpeg&quot;, height = 5, width = 5) 2.3 Study area imagery let’s look at the RGB imagery and pile locations # get the base plot plt_rgb_ortho &lt;- ortho_plt_fn( slash_piles_points %&gt;% sf::st_bbox() %&gt;% sf::st_as_sfc() %&gt;% sf::st_buffer(50) %&gt;% sf::st_transform(terra::crs(ortho_rast)) ) # add pile locations plt_rgb_ortho + ggplot2::geom_sf( data = slash_piles_points %&gt;% sf::st_transform(terra::crs(ortho_rast)) , ggplot2::aes() # size = diameter , shape = 1 , color = &quot;firebrick&quot; ) + ggplot2::theme(legend.position = &quot;none&quot;) notice these are point measurements of plot locations and the points are not precisely in the center of the pile. notice also there are piles in the imagery that were not measured (e.g. upper-left corner) Update: we created image-annotated pile polygons using the RBG and field-collected pile location data let’s make a panel of plots for each pile p_fn_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , crs = terra::crs(ortho_rast) ) { # scale the buffer based on the largest d &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt ortho_plt_fn(d) + ggplot2::geom_sf(data = d, fill = NA, color = &quot;firebrick&quot;) + ggplot2::labs( subtitle = paste0( tolower(d$comment) , &quot;\\ndiam. = &quot; , scales::comma(d$diameter, accuracy = 0.1) # , &quot;, ht. = &quot; # , scales::comma(d$height, accuracy = 0.1) ) ) } # add pile locations plt_list_rgb &lt;- 1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))) %&gt;% purrr::map(p_fn_temp) plot tiles patchwork::wrap_plots( sample( plt_list_rgb, size = as.integer(nrow(slash_piles_points)/3)) , ncol = 5 ) ggsave(&quot;../data/pile_tiles_rgb.jpeg&quot;, height = 10.5, width = 8) object-based image analysis will require polygon data so that we have sets of pixels (i.e. “objects”) to work with for training our model (nice, we’ll use the image-annotated pile data) another challenge will be training a spectral-based model with the different lighting conditions in the imagery (e.g. piles in shadows or under tree crowns). this different lighting may have also influenced the point cloud generation 2.4 Point Cloud Data Let’s check out the point cloud data we got using UAS-SfM methods # directory with the downloaded .las|.laz files f_temp &lt;- &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; # system.file(package = &quot;lidR&quot;, &quot;extdata&quot;, &quot;Megaplot.laz&quot;) # is there data? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;) %&gt;% length() ## [1] 1 # what files are in here? list.files(f_temp, pattern = &quot;.*\\\\.(laz|las)$&quot;)[1] ## [1] &quot;P4Pro_06_17_2021_half_half_optimal_group1_densified_point_cloud.las&quot; what information does lidR read from the catalog? las_ctg &lt;- lidR::readLAScatalog(f_temp) # set the processing options lidR::opt_progress(las_ctg) &lt;- F lidR::opt_filter(las_ctg) &lt;- &quot;-drop_duplicates&quot; lidR::opt_select(las_ctg) &lt;- &quot;xyziRGB&quot; # huh? las_ctg ## class : LAScatalog (v1.2 format 3) ## extent : 499264.2, 499958.8, 4317541, 4318147 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N ## area : 420912.1 m² ## points : 158.01 million points ## density : 375.4 points/m² ## num. files : 1 that’s a lot of points…can an ordinary laptop handle it? we’ll find out. We’ll plot our point cloud data tiles real quick to orient ourselves las_ctg %&gt;% purrr::pluck(&quot;data&quot;) %&gt;% mapview::mapview(popup = F, layer.name = &quot;point cloud tile&quot;) 2.5 Check out one pile las_temp &lt;- lidR::clip_roi( las_ctg # biggest mechanical , slash_piles_points %&gt;% dplyr::filter(tolower(comment)==&quot;mechanical pile&quot;) %&gt;% dplyr::arrange(desc(diameter)) %&gt;% dplyr::slice(1) %&gt;% sf::st_zm() %&gt;% sf::st_buffer(10, endCapStyle = &quot;SQUARE&quot;) %&gt;% sf::st_transform(lidR::st_crs(las_ctg)) ) what did we get? las_temp@data %&gt;% dplyr::glimpse() ## Rows: 181,282 ## Columns: 7 ## $ X &lt;dbl&gt; 499807.0, 499807.0, 499807.0, 499807.0, 499807.0, 499807.0, … ## $ Y &lt;dbl&gt; 4317975, 4317975, 4317975, 4317975, 4317975, 4317975, 431797… ## $ Z &lt;dbl&gt; 2714.829, 2714.777, 2714.709, 2714.900, 2714.636, 2714.594, … ## $ Intensity &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, … ## $ R &lt;int&gt; 20224, 16896, 32256, 44288, 21760, 16896, 14592, 35584, 3148… ## $ G &lt;int&gt; 18176, 16640, 34304, 40960, 20480, 14848, 8704, 34048, 34304… ## $ B &lt;int&gt; 16384, 16384, 33280, 36608, 20992, 14336, 7168, 33280, 35072… plot a sample las_temp %&gt;% lidR::plot( color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) make a gif library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_z.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;Z&quot;, bg = &quot;white&quot;, legend = F , pal = harrypotter::hp(n=50, house = &quot;gryffindor&quot;) ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_z&quot;, dir = &quot;../data/&quot;) rgl::close3d() } library(magick) if(!file.exists(file.path(&quot;../data/&quot;, &quot;pile_rgb.gif&quot;))){ rgl::close3d() lidR::plot( las_temp, color = &quot;RGB&quot;, bg = &quot;white&quot;, legend = F ) rgl::movie3d( rgl::spin3d(), duration = 10, fps = 10 , movie = &quot;pile_rgb&quot;, dir = &quot;../data/&quot;) rgl::close3d() } "],["rgb-classification.html", "Section 3 RGB Classification 3.1 Textural covariates 3.2 Pixel-based: unsupervised classification 3.3 Pixel-based: supervised classification 3.4 Object-based image analysis (OBIA)", " Section 3 RGB Classification We’ll use the RGB imagery alone to explore unsupervised and supervised classification algorithms. Ultimately, it is likely we will use an object-based image analysis (OBIA) approach. OBIA is a technique (or a set of techniques) used to analyze digital images that was developed relatively recently in comparison to ‘classic’ pixel-based image approaches (Burnett and Blaschke 2003). The OBIA approach for ecological applications is described by Goncalves et al. (2019) who also introduce the SegOptim package In future sections we will explore, integration of spectral data with the 3D point cloud data (i.e. “data fusion”) to test distinguishing the woody material in slash piles from surrounding vegetation or soil. Field-measured slash piles will be used as the ground truth data to perform a confusion matrix-based validation accuracy assessment of the methods. Norton et al. (2022) combined LiDAR and hyperspectral data in a data fusion approach for classification of semi-arid woody cover species and achieved accuracies ranging from 86% to 98% for five woody species We’ll see how far we can get without hyperspectral data since this data is less common 3.1 Textural covariates Haralick et al. (2007) describe how quantitative measures of image texture can help distinguish between different imagery patterns that might have similar spectral signatures but distinct textures (e.g. vegetation types, habitat structures, or disturbance patterns). These textural features are typically calculated on a single-band grayscale image (i.e. panchromatic) but can also be calculated from spectral indicies (e.g. NDVI). Common Haralick statistics include: mean (average pixel value within the window), variance (variation in pixel values), homogeneity, contrast, and entropy (the randomness or disorder of the image) Rodman et al. (2019) also describe a method using a series of image processing steps to add supplemental information describing the texture and context surrounding each image pixel in their analysis of forest cover change based only on panchromatic imagery (i.e. “black and white”). These textural covariates may be helpful for identifying slash piles, especially if we only have RGB data. first, we’ll make a single panchromatic band (the mean of red, green, and blue values) from our RGB imagery rgb_to_pan_fn &lt;- function(r, g, b) { pan &lt;- (r + g + b)/3 # replace all 0&#39;s with na pan &lt;- terra::subst(pan, from = 0, to = NA) return(pan) } panchromatic_rast &lt;- rgb_to_pan_fn( ortho_rast[[1]], ortho_rast[[2]], ortho_rast[[3]] ) quick plot terra::plot( panchromatic_rast , col = scales::pal_grey(0, 1)(100) , axes=F, legend = F ) nice, now we’ll make the textural covariates described by Rodman et al. (2019) in Appendix S2 rast_rodmanetal2019_fn &lt;- function( rast, windows_m = c(3,5,7,9,11,13,15), scale_to_1m = T , rast_nm = &quot;panchromatic&quot; ) { rast &lt;- rast[[1]] # scale the windows based on resolution if(scale_to_1m){ windows_m &lt;- round_to_nearest_odd( (1/terra::res(rast)[1])*windows_m ) }else{ windows_m &lt;- round_to_nearest_odd(windows_m) } ################################ # means ################################ r_means &lt;- windows_m %&gt;% purrr::map(\\(w) terra::focal(x = rast, w = w, fun = &quot;mean&quot;, na.rm = T) ) # r_means[[7]] %&gt;% terra::plot(col = scales::pal_grey(0, 1)(100)) ################################ # sds ################################ r_sds &lt;- windows_m %&gt;% purrr::map(\\(w) terra::focal(x = rast, w = w, fun = &quot;sd&quot;, na.rm = T) ) # r_sds[[5]] %&gt;% terra::plot(col = scales::pal_grey(0, 1)(100)) ################################ # local min ################################ local_min_fn &lt;- function(rast, mean, sd) { as.numeric(rast &lt; ( mean-(sd*2) )) } r_local_min &lt;- 1:length(r_means) %&gt;% purrr::map(\\(i) local_min_fn(rast = rast, mean = r_means[[i]], sd = r_sds[[i]]) ) # r_local_min[[5]] %&gt;% terra::plot() ################################ # local coefficient of variation ################################ local_cv_fn &lt;- function(mean, sd) { terra::clamp(sd/mean, lower = 0, upper = 1, values = T) } r_local_cv &lt;- 1:length(r_means) %&gt;% purrr::map(\\(i) local_cv_fn(mean = r_means[[i]], sd = r_sds[[i]]) ) # r_local_min[[5]] %&gt;% terra::plot() ################################ # aggregate local min ################################ r_local_min_agg &lt;- terra::rast(r_local_min) %&gt;% cumsum() # get the last of the local mins local_minima &lt;- r_local_min_agg[[terra::nlyr(r_local_min_agg)]] ################################ # aggregate local cv ################################ r_local_cv_agg &lt;- terra::rast(r_local_cv) %&gt;% cumsum() # get the last of the local cvs local_cv &lt;- r_local_cv_agg[[terra::nlyr(r_local_cv_agg)]] ################################ # aggregate local sd ################################ r_sds_agg &lt;- terra::rast(r_sds) %&gt;% cumsum() # get the last of the local sds local_sd &lt;- r_sds_agg[[terra::nlyr(r_sds_agg)]] ################################ # aggregate local mean ################################ r_means_agg &lt;- terra::rast(r_means) %&gt;% cumsum() # get the last of the local mean local_mean &lt;- r_means_agg[[terra::nlyr(r_means_agg)]] ################################ # composite ################################ composite &lt;- c(rast, local_sd, local_minima) names(composite) &lt;- c(rast_nm, &quot;local_sd&quot;, &quot;local_minima&quot;) # names names(local_minima) &lt;- c(&quot;local_minima&quot;) names(local_sd) &lt;- c(&quot;local_sd&quot;) return(list( local_minima = local_minima , local_sd = local_sd , local_mean = local_mean , local_cv = local_cv , composite = composite )) } 3.1.1 Raster Texture: Panchromatic implement our rast_rodmanetal2019_fn function rodmanetal2019_panchromatic_rast &lt;- rast_rodmanetal2019_fn( rast = panchromatic_rast , rast_nm = &quot;panchromatic&quot; , scale_to_1m = F ) plot of standard deviation pixel brightness which is a simple version of local texture that can improve forest classification in high-resolution imagery terra::plot( rodmanetal2019_panchromatic_rast$local_sd , col = scales::pal_grey(0, 1)(100) , axes=F, legend = F ) plot of these combined panchromatic, local minima, and standard deviation images were merged to create a three-band composite which can be segmented to identify areas of relatively homogeneous brightness, contrast, and variance terra::plotRGB( rodmanetal2019_panchromatic_rast$composite # , scale = c(255,7,520) , stretch = &quot;hist&quot;, colNA = &quot;transparent&quot; ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) 3.1.2 Raster Texture: GRVI implement our rast_rodmanetal2019_fn function rodmanetal2019_grvi_rast &lt;- rast_rodmanetal2019_fn( rast = grvi_rast , rast_nm = &quot;grvi&quot; , scale_to_1m = F ) plot of these combined GRVI terra::plotRGB( rodmanetal2019_grvi_rast$composite # , scale = c(255,7,520) , stretch = &quot;hist&quot;, colNA = &quot;transparent&quot; ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) check out the local CV of GRVI terra::plot( rodmanetal2019_grvi_rast$local_cv , col = scales::pal_grey(0, 1)(100) , axes=F, legend = F ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA ) this metric looks promising as it indicates that piles are generally in areas with low CV…which indicates low variability, meaning the GRVI values are tightly clustered around the focal mean, suggesting consistency and stability. 3.1.3 Plot textural rasters let’s look at these textural rasters for some of the piles p_fn_temp &lt;- function( rn , df = slash_piles_polys , composite_rast = rodmanetal2019_grvi_rast$composite , crs = terra::crs(ortho_rast) , my_title = &quot;&quot; ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt classifier # convert to stars comp_st &lt;- composite_rast %&gt;% terra::subset(subset = c(1,2,3)) %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(20) %&gt;% terra::vect() ) %&gt;% # terra::aggregate(fact = 2, fun = &quot;mean&quot;, na.rm = T) %&gt;% stars::st_as_stars() # convert to rgb comp_rgb &lt;- stars::st_rgb( comp_st[,,,1:3] , dimension = 3 , use_alpha = FALSE # , stretch = &quot;histogram&quot; , probs = c(0.002, 0.998) , stretch = &quot;percent&quot; ) # ggplot comp_temp &lt;- ggplot2::ggplot() + stars::geom_stars(data = comp_rgb[]) + ggplot2::scale_fill_identity(na.value = &quot;transparent&quot;) + # !!! don&#39;t take this out or RGB plot will kill your computer ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 0.3) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , subtitle = my_title ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;none&quot; # c(0.5,1) , legend.direction = &quot;horizontal&quot; , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 8) , legend.title = element_text(size = 8) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) plt_temp &lt;- comp_temp return(list(&quot;plt&quot;=plt_temp,&quot;d&quot;=d_temp)) } # combine 3 plt_combine_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , composite_rast1 = rodmanetal2019_panchromatic_rast$composite , title1 = &quot;panchromatic composite&quot; , composite_rast2 = rodmanetal2019_grvi_rast$composite , title2 = &quot;GRVI composite&quot; , crs = terra::crs(ortho_rast) ) { # composite 1 ans1 &lt;- p_fn_temp( rn = rn , df = df , composite_rast = composite_rast1 , my_title = title1 , crs = crs ) # composite 2 ans2 &lt;- p_fn_temp( rn = rn , df = df , composite_rast = composite_rast2 , my_title = title2 , crs = crs ) # plt rgb rgb_temp &lt;- ortho_plt_fn(ans1$d) + ggplot2::geom_sf(data = ans1$d, fill = NA, color = &quot;white&quot;, lwd = 0.3) # combine r &lt;- ans1$plt + ans2$plt + rgb_temp return(r) } # add pile locations plt_list_grvi_comp &lt;- sample(1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))),10) %&gt;% purrr::map(plt_combine_temp) # plt_list_grvi_comp[[2]] combine the plots for a few piles patchwork::wrap_plots( plt_list_grvi_comp , ncol = 1 ) ggplot2::ggsave(&quot;../data/pile_tiles_texture.jpeg&quot;, height = 10.5, width = 5) 3.1.4 Features for classification Goncalves et al. (2019) describe the general workflow of the OBIA approach for ecological applications based on Genetic Algorithms (GA) to optimize image segmentation parameters: Run the image segmentation: involves the partitioning of an image into a set of jointly exhaustive and mutually disjoint regions (a.k.a. segments, composed by multiple image pixels) that are internally more homogeneous and similar compared to adjacent ones; segmentation algorithms include: mean-shift; region growing; SNIC (Simple Non-iterative Clustering) and SLIC (Simple Linear Iterative Clustering) Load training data into the segmented image; Calculate segment statistics (e.g., mean, standard-deviation) for classification features; Merge training and segment statistics data (steps 2-3); Do train/test data partitions (e.g., 5-fold cross-validation); For each train/test set: 6.1. Train the supervised classifier; 6.2. Evaluate results for the test set; Return the average evaluation score across all train/test rounds (fitness value); where: Segmentation features (step 1): a multi-layer raster dataset with features used only for the segmentation stage (e.g., spectral bands) Classification features (step 3): a multi-layer raster dataset with features used for classification (e.g., spectral data, band ratios, spectral vegetation indices, texture features, topographic data). let’s combine our rasters into a raster stack and generate a data frame with individual cells as rows and covariates as columns #rename composites names(rodmanetal2019_panchromatic_rast$composite) &lt;- c( &quot;panchromatic&quot;, &quot;panchromatic_local_sd&quot;, &quot;panchromatic_local_minima&quot; ) names(rodmanetal2019_panchromatic_rast$local_cv) &lt;- c( &quot;panchromatic_local_cv&quot; ) names(rodmanetal2019_grvi_rast$composite) &lt;- c( &quot;grvi&quot;, &quot;grvi_local_sd&quot;, &quot;grvi_local_minima&quot; ) names(rodmanetal2019_grvi_rast$local_cv) &lt;- c( &quot;grvi_local_cv&quot; ) # raster stack pred_rast &lt;- c( terra::subset(ortho_rast, c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)) , rodmanetal2019_panchromatic_rast$composite , rodmanetal2019_panchromatic_rast$local_cv , rodmanetal2019_grvi_rast$composite , rodmanetal2019_grvi_rast$local_cv ) # pred_rast %&gt;% names() check out correlations between covariates # investigate correlation among covariates pred_rast %&gt;% terra::pairs( maxcells = min(7777, terra::ncell(pred_rast)*.01) ) the panchromatic band itself doesn’t add much new information, let’s remove it and generate a data frame for training our clustering algorithms # remove correlated layers pred_rast &lt;- terra::subset( pred_rast , subset = c(&quot;panchromatic&quot;) , negate = T ) # combine rasters as data frame pred_df &lt;- terra::as.data.frame( pred_rast , xy = T , cell = T ) %&gt;% dplyr::mutate( dplyr::across( .cols = c(red,green,blue) , .fns = ~ ifelse(.x==0,NA,.x) ) ) # what is this data? pred_df %&gt;% dplyr::slice_sample(n=100) %&gt;% dplyr::glimpse() ## Rows: 100 ## Columns: 13 ## $ cell &lt;dbl&gt; 1134877, 4376337, 4716450, 907889, 5481369, … ## $ x &lt;dbl&gt; 499652.6, 499593.4, 499277.9, 499573.9, 4993… ## $ y &lt;dbl&gt; 4318035, 4317739, 4317707, 4318056, 4317637,… ## $ red &lt;dbl&gt; 123.54051, 187.04930, 158.08899, 38.94115, 4… ## $ green &lt;dbl&gt; 131.36421, 185.40657, 155.71065, 43.27213, 5… ## $ blue &lt;dbl&gt; 102.75333, 166.89407, 144.25243, 40.42112, 3… ## $ panchromatic_local_sd &lt;dbl&gt; 175.70954, 97.13799, 93.57156, 342.48163, 17… ## $ panchromatic_local_minima &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 3, 0,… ## $ panchromatic_local_cv &lt;dbl&gt; 1.6515966, 0.6080894, 0.6583037, 5.1816120, … ## $ grvi &lt;dbl&gt; 0.030692644, -0.004410538, -0.007579173, 0.0… ## $ grvi_local_sd &lt;dbl&gt; 0.09930567, 0.07430560, 0.15033831, 0.383822… ## $ grvi_local_minima &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ grvi_local_cv &lt;dbl&gt; 2.795572, 0.000000, 0.000000, 6.514303, 7.00… 3.2 Pixel-based: unsupervised classification Unsupervised image classification could be used to identify slash piles by grouping pixels with similar spectral characteristics. We’ll call any method that implements classification at the pixel level like the unsupervised classification approach tested here “pixel-based image analysis” versus to OBIA. Unsupervised image classification uses algorithms like K-means to find natural clusters within spectral data and can use other inputs like elevation or spectral indices. This method operates without requiring pre-defined training data, making it useful when field data is limited. The output assigns each pixel to a class, which the user then interprets to potentially identify slash piles based on their distinct spectral signatures and elevated height. While effective for initial classification and pattern recognition, unsupervised methods can produce numerous classes that require manual interpretation and may be less accurate than supervised approaches without ground truth data. let’s test out kmeans clustering and see what we get set.seed(111) # Create 6 clusters, allow 500 iterations, start with 5 random sets using &quot;Lloyd&quot; kmncluster &lt;- stats::kmeans( pred_df %&gt;% dplyr::select(-c(cell,x,y)) %&gt;% # we can&#39;t have NA values in kmeans dplyr::mutate( dplyr::across( .cols = dplyr::everything() , .fns = ~ as.numeric(ifelse(is.na(.x),-99,.x)) ) ) , centers=6 , iter.max = 500 , nstart = 5 , algorithm=&quot;Lloyd&quot; ) # kmeans returns an object of class kmeans str(kmncluster) ## List of 9 ## $ cluster : Named int [1:5844340] 1 1 1 1 1 1 1 1 1 1 ... ## ..- attr(*, &quot;names&quot;)= chr [1:5844340] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ centers : num [1:6, 1:10] -99 141.9 108.1 32.6 163.2 ... ## ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. ..$ : chr [1:6] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. ..$ : chr [1:10] &quot;red&quot; &quot;green&quot; &quot;blue&quot; &quot;panchromatic_local_sd&quot; ... ## $ totss : num 1.22e+11 ## $ withinss : num [1:6] 1.16e+08 3.17e+09 2.94e+09 2.81e+09 4.61e+09 ... ## $ tot.withinss: num 1.68e+10 ## $ betweenss : num 1.05e+11 ## $ size : int [1:6] 198257 777040 1349009 905046 1899184 715804 ## $ iter : int 57 ## $ ifault : NULL ## - attr(*, &quot;class&quot;)= chr &quot;kmeans&quot; put the kmeans clusters into a raster # make a blank raster kmeans_cluster_rast &lt;- terra::rast(ortho_rast, nlyr=1) # fill the raster kmeans_cluster_rast[pred_df$cell] &lt;- kmncluster$cluster # what? kmeans_cluster_rast ## class : SpatRaster ## dimensions : 2140, 2731, 1 (nrow, ncol, nlyr) ## resolution : 0.25, 0.25 (x, y) ## extent : 499274.8, 499957.5, 4317604, 4318139 (xmin, xmax, ymin, ymax) ## coord. ref. : WGS 84 / UTM zone 13N (EPSG:32613) ## source(s) : memory ## name : lyr1 ## min value : 1 ## max value : 6 there should be at most 6 clusters terra::freq(kmeans_cluster_rast) ## layer value count ## 1 1 1 198257 ## 2 1 2 777040 ## 3 1 3 1349009 ## 4 1 4 905046 ## 5 1 5 1899184 ## 6 1 6 715804 plot the kmeans unsupervised classfication result terra::plot( kmeans_cluster_rast , col = viridis::turbo(n=6) , axes=F, legend = F ) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA ) neat, let’s see if the piles are classified by making a custom function to plot the classified raster and RGB side-by-side p_fn_temp &lt;- function( rn , df = slash_piles_polys %&gt;% dplyr::filter(!is.na(comment)) , cluster_rast = kmeans_cluster_rast , crs = terra::crs(ortho_rast) ) { # scale the buffer based on the largest d_temp &lt;- df %&gt;% dplyr::arrange(tolower(comment), desc(diameter)) %&gt;% dplyr::slice(rn) %&gt;% sf::st_transform(crs) # plt rgb_temp &lt;- ortho_plt_fn(d_temp) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 1) # plt classifier class_temp &lt;- ggplot2::ggplot() + ggplot2::geom_tile( data = cluster_rast %&gt;% terra::crop( d_temp %&gt;% sf::st_buffer(20) %&gt;% terra::vect() ) %&gt;% terra::as.data.frame(xy=T) %&gt;% dplyr::rename(f=3) , ggplot2::aes(x=x,y=y,fill=as.factor(f)) ) + ggplot2::geom_sf(data = d_temp, fill = NA, color = &quot;white&quot;, lwd = 1) + ggplot2::scale_fill_manual( values = c( &quot;1&quot; = viridis::turbo(n=6)[1] , &quot;2&quot; = viridis::turbo(n=6)[2] , &quot;3&quot; = viridis::turbo(n=6)[3] , &quot;4&quot; = viridis::turbo(n=6)[4] , &quot;5&quot; = viridis::turbo(n=6)[5] , &quot;6&quot; = viridis::turbo(n=6)[6] # , &quot;7&quot; = viridis::turbo(n=10)[7] # , &quot;8&quot; = viridis::turbo(n=10)[8] # , &quot;9&quot; = viridis::turbo(n=10)[9] # , &quot;10&quot; = viridis::turbo(n=10)[10] ) , na.value = &quot;transparent&quot; ) + ggplot2::scale_x_continuous(expand = c(0, 0)) + ggplot2::scale_y_continuous(expand = c(0, 0)) + ggplot2::labs( x = &quot;&quot; , y = &quot;&quot; , fill = &quot;&quot; ) + ggplot2::theme_void() + ggplot2::theme( legend.position = &quot;left&quot; # c(0.5,1) , legend.margin = margin(0,0,0,0) , legend.text = element_text(size = 6) , legend.title = element_text(size = 6) , legend.key = element_rect(fill = &quot;white&quot;) # , plot.title = ggtext::element_markdown(size = 10, hjust = 0.5) , plot.title = element_text(size = 8, hjust = 0.5, face = &quot;bold&quot;) , plot.subtitle = element_text(size = 6, hjust = 0.5, face = &quot;italic&quot;) ) plt_temp &lt;- class_temp+rgb_temp return(plt_temp) } # add pile locations plt_list_kmeans &lt;- sample(1:nrow(slash_piles_polys %&gt;% dplyr::filter(!is.na(comment))),10) %&gt;% purrr::map(p_fn_temp) combine the plots for a few piles patchwork::wrap_plots( plt_list_kmeans , ncol = 2 , guides = &quot;collect&quot; ) ggplot2::ggsave(&quot;../data/pile_tiles_kmeans6.jpeg&quot;, height = 10.5, width = 8) there is no discernible pattern between the kmeans classes and the slash piles because the lighting and conditions around the piles are not consistent. this result also highlights the challenges we’ll likely face with pixel-based classification methods 3.3 Pixel-based: supervised classification we’ll start with a pixel-based classification using the image-annotated pile polygons to train a classification model first, let’s set aside some piles for use in validation set.seed(333) # 20% will be used for validation slash_piles_polys &lt;- slash_piles_polys %&gt;% dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::filter(!is.na(comment)) %&gt;% dplyr::distinct(pile_id) %&gt;% dplyr::slice_sample(prop = 0.2) %&gt;% dplyr::mutate(is_training = F) , by = &quot;pile_id&quot; ) %&gt;% dplyr::mutate(is_training = dplyr::coalesce(is_training, T)) slash_piles_points &lt;- slash_piles_points %&gt;% dplyr::left_join( slash_piles_polys %&gt;% sf::st_drop_geometry() %&gt;% dplyr::distinct(objectid, is_training) , by = &quot;objectid&quot; ) # slash_piles_points %&gt;% sf::st_drop_geometry() %&gt;% dplyr::count(is_training) first, we’ll generate a set of sample points to extract raster values from to build our training data with covariates training_points &lt;- dplyr::bind_rows( # sample only from non-pile parts of the raster terra::mask( grvi_rast , slash_piles_polys %&gt;% # use ALL piles (image-annotated and field-collected) sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , inverse = T ) %&gt;% terra::spatSample(size = 5000, na.rm = T, xy = T) %&gt;% sf::st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;), crs = terra::crs(grvi_rast)) %&gt;% dplyr::mutate( is_pile = 0 ) %&gt;% dplyr::select(is_pile) # sample points within piles , slash_piles_polys %&gt;% dplyr::filter( is_training ) %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() %&gt;% terra::spatSample(size = 1000) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate( is_pile = 1 ) %&gt;% dplyr::select(is_pile) ) %&gt;% dplyr::mutate( id = dplyr::row_number() , is_pile = as.factor(is_pile) , x = sf::st_coordinates(.)[,1] , y = sf::st_coordinates(.)[,2] ) ####### validation points since we&#39;ll validate at the pixel level validation_points &lt;- dplyr::bind_rows( # sample only from non-pile parts of the raster terra::mask( grvi_rast , slash_piles_polys %&gt;% # use ALL piles (image-annotated and field-collected) sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() , inverse = T ) %&gt;% # mask the training points as well terra::mask( training_points %&gt;% terra::vect() , inverse = T ) %&gt;% terra::spatSample(size = 5000, na.rm = T, xy = T) %&gt;% sf::st_as_sf(coords = c(&quot;x&quot;, &quot;y&quot;), crs = terra::crs(grvi_rast)) %&gt;% dplyr::mutate( is_pile = 0 ) %&gt;% dplyr::select(is_pile) # sample points within piles , slash_piles_polys %&gt;% dplyr::filter( !is_training ) %&gt;% sf::st_transform(terra::crs(grvi_rast)) %&gt;% terra::vect() %&gt;% terra::spatSample(size = 1000) %&gt;% sf::st_as_sf() %&gt;% dplyr::mutate( is_pile = 1 ) %&gt;% dplyr::select(is_pile) ) %&gt;% dplyr::mutate( id = dplyr::row_number() , is_pile = as.factor(is_pile) , x = sf::st_coordinates(.)[,1] , y = sf::st_coordinates(.)[,2] ) plot our RGB with training piles (white), validation piles (black), pile sample points (red), and non-pile sample points (blue) # let&#39;s check this out terra::plotRGB(ortho_rast, stretch = &quot;lin&quot;, colNA = &quot;transparent&quot;) terra::plot( slash_piles_polys %&gt;% dplyr::filter(is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% dplyr::filter(!is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) terra::plot(training_points %&gt;% dplyr::filter(is_pile==1) %&gt;% terra::vect(), col = &quot;red&quot;, cex = 0.5, add = T) terra::plot(training_points %&gt;% dplyr::filter(is_pile==0) %&gt;% terra::vect(), col = &quot;blue&quot;, cex = 0.5, add = T) extract the raster cell values from each layer in our RGB-based raster data, these values will be the predictor variables ############################# #extract covariate data at point locations ############################# training_df &lt;- terra::extract( pred_rast , training_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::bind_cols( training_points %&gt;% dplyr::select(id,is_pile,x,y) ) %&gt;% ## make sure no data is missing dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.x))) # ## square continuous vars? # dplyr::mutate(dplyr::across( # .cols = dplyr::where(is.numeric) &amp; !c(id, is_pile, x, y) &amp; !tidyselect::ends_with(&quot;local_minima&quot;) # , .fns = list(sq) # , .names = &quot;{.col}_sq&quot; # )) ##### and validation data to perform accuracy assesment at the pixel level validation_dta &lt;- terra::extract( pred_rast , validation_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::bind_cols( validation_points %&gt;% dplyr::select(id,is_pile,x,y) ) %&gt;% ## make sure no data is missing dplyr::filter(dplyr::if_all(dplyr::everything(), ~ !is.na(.x))) # ## square continuous vars? # dplyr::mutate(dplyr::across( # .cols = dplyr::where(is.numeric) &amp; !c(id, is_pile, x, y) &amp; !tidyselect::ends_with(&quot;local_minima&quot;) # , .fns = list(sq) # , .names = &quot;{.col}_sq&quot; # )) compare training and validation data to ensure that they are similar (i.e. we drew a big enough sample) dplyr::bind_rows( training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate(dta_set = &quot;Training&quot;) , validation_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::mutate(dta_set = &quot;Validation&quot;) ) %&gt;% dplyr::select(-c(geometry,dplyr::ends_with(&quot;_sq&quot;))) %&gt;% dplyr::mutate_if(is.factor, as.numeric) %&gt;% tidyr::pivot_longer( cols = -c(id, is_pile, dta_set) , names_to = &quot;covariate&quot; , values_to = &quot;value&quot; ) %&gt;% dplyr::mutate(covariate = stringr::str_replace_all(covariate,&quot;_&quot;, &quot; &quot;)) %&gt;% ggplot(mapping = aes(x = value, color = dta_set, fill = dta_set, group = dta_set)) + geom_density(alpha=0.6) + facet_wrap( facets = vars(covariate), scales = &quot;free&quot; , labeller = label_wrap_gen(width = 25, multi_line = TRUE) ) + scale_color_viridis_d(option = &quot;cividis&quot;) + scale_fill_viridis_d(option = &quot;cividis&quot;) + labs( title = &quot;Distribution of Model Covariates&quot; , subtitle = paste0( &quot;by Training (n=&quot; , nrow(training_df) %&gt;% scales::comma(accuracy = 1) , &quot;) and Validation (n=&quot; , nrow(validation_dta) %&gt;% scales::comma(accuracy = 1) , &quot;) data&quot; ) ) + theme_light() + theme( legend.position = &quot;top&quot; , legend.title = element_blank() , plot.title = element_text(size = 10) , plot.subtitle = element_text(size = 9) , axis.title = element_text(size = 7) , axis.text = element_text(size = 6) ) + guides(color = guide_legend(override.aes = list(size = 5))) we’ll use a random forest model to predict raster values # Tune on the full data if below threshold tune_result_temp &lt;- randomForest::tuneRF( y = training_df$is_pile , x = training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(id,is_pile,geometry)) , ntreeTry = 500 , stepFactor = 1 , improve = 0.03 , plot = F , trace = F ) # Extract the optimal mtry value optimal_mtry_temp &lt;- tune_result_temp %&gt;% dplyr::as_tibble() %&gt;% dplyr::filter(OOBError==min(OOBError)) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::pull(mtry) %&gt;% as.numeric() # pass to random forest model mod_rf &lt;- randomForest::randomForest( y = training_df$is_pile , x = training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(id,is_pile,geometry)) , mtry = optimal_mtry_temp , na.action = na.omit , ntree = 500 ) random forest variable importance plot #variable importance plot randomForest::varImpPlot(mod_rf) predict raster values # x,y rasters y_rast_temp &lt;- terra::init(pred_rast[[1]], &quot;y&quot;) names(y_rast_temp) &lt;- &quot;y&quot; x_rast_temp &lt;- terra::init(pred_rast[[1]], &quot;x&quot;) names(x_rast_temp) &lt;- &quot;x&quot; # predict rf_pred_rast &lt;- terra::predict( object = c( pred_rast , x_rast_temp, y_rast_temp ) , model = mod_rf , na.rm = T # , type = &quot;prob&quot; ) terra::coltab(rf_pred_rast) &lt;- data.frame(value=1:2, col=c(&quot;gray&quot;, &quot;khaki&quot;)) levels(rf_pred_rast) &lt;- data.frame(value=1:2, col=c(&quot;non-pile&quot;, &quot;pile&quot;)) plot pixel-level predictions #plot terra::plot(rf_pred_rast) terra::plot( slash_piles_polys %&gt;% dplyr::filter(is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;white&quot;, col = NA, lwd = 1.2 ) terra::plot( slash_piles_polys %&gt;% dplyr::filter(!is_training) %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;black&quot;, col = NA, lwd = 1.2 ) evaluate model performance based on the Area under the Receiver Operating Characteristic (ROC) Curve (AUC) criterion (an AUC value of 0.5 can be interpreted as the model performing no better than a random prediction). Higher AUC values indicate that the model is better at predicting “absence” classes as “absence” (true negative) and “presence” classes as “presence” (true positive). validation_dta &lt;- validation_dta %&gt;% dplyr::bind_cols( terra::extract( rf_pred_rast , validation_points %&gt;% terra::vect() , ID = F ) %&gt;% dplyr::rename(is_pile_predicted=1) ) PresenceAbsence::auc.roc.plot( validation_dta %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(id, is_pile, is_pile_predicted) %&gt;% dplyr::mutate(dplyr::across(tidyselect::starts_with(&quot;is_pile&quot;), ~ as.numeric(.x)-1 )) , main = &quot;Random Forest&quot; ) now lets check the confusion matrix of the pixel-based approach confusion_matrix_temp &lt;- validation_dta %&gt;% dplyr::mutate(dplyr::across(tidyselect::starts_with(&quot;is_pile&quot;), ~ as.numeric(.x)-1 )) %&gt;% dplyr::rename( presence = is_pile , estimate = is_pile_predicted ) %&gt;% dplyr::count(presence,estimate) %&gt;% dplyr::mutate( is_false = as.factor(ifelse(presence!=estimate,1,0)) , presence_fact = factor(presence,levels = 0:1,labels = c(&quot;Observed Absent&quot;, &quot;Observed Present&quot;)) , estimate_fact = factor(estimate,levels = 0:1,labels = c(&quot;Predicted Absent&quot;, &quot;Predicted Present&quot;)) , pct = n/sum(n) ) # first function takes df with cols tp_n, fp_n, and fn_n to calculate rate confusion_matrix_scores_fn &lt;- function(df) { df %&gt;% dplyr::mutate( omission_rate = dplyr::case_when( (tp_n+fn_n) == 0 ~ as.numeric(NA) , T ~ fn_n/(tp_n+fn_n) ) # False Negative Rate or Miss Rate , commission_rate = dplyr::case_when( (tp_n+fp_n) == 0 ~ as.numeric(NA) , T ~ fp_n/(tp_n+fp_n) ) # False Positive Rate , precision = dplyr::case_when( (tp_n+fp_n) == 0 ~ as.numeric(NA) , T ~ tp_n/(tp_n+fp_n) ) , recall = dplyr::case_when( (tp_n+fn_n) == 0 ~ as.numeric(NA) , T ~ tp_n/(tp_n+fn_n) ) , f_score = dplyr::case_when( is.na(precision) | is.na(recall) ~ as.numeric(NA) , (precision+recall) == 0 ~ 0 , T ~ 2 * ( (precision*recall)/(precision+recall) ) ) ) } confusion_matrix_scores_temp &lt;- confusion_matrix_scores_fn( dplyr::tibble( tp_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==1 &amp; estimate == 1) %&gt;% dplyr::pull(n) , fn_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==1 &amp; estimate == 0) %&gt;% dplyr::pull(n) , fp_n = confusion_matrix_temp %&gt;% dplyr::filter(presence==0 &amp; estimate == 1) %&gt;% dplyr::pull(n) ) ) # plot ggplot(data = confusion_matrix_temp, mapping = aes(y = estimate_fact, x = presence_fact)) + geom_tile(aes(fill = is_false), color = &quot;white&quot;,alpha=0.8) + geom_text(aes(label = scales::comma(n,accuracy=1)), vjust = 1,size = 8) + geom_text(aes(label = scales::percent(pct,accuracy=0.1)), vjust = 3.5, size=5) + scale_fill_manual(values= c(&quot;turquoise&quot;,&quot;tomato2&quot;)) + scale_x_discrete(position = &quot;top&quot;) + labs( y = &quot;Predicted&quot; , x = &quot;Observed&quot; , subtitle = paste0( &quot;True positive rate (recall) = &quot; , confusion_matrix_scores_temp$recall %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nPrecision (PPV) = &quot; , confusion_matrix_scores_temp$precision %&gt;% scales::percent(accuracy = 0.1) , &quot;\\nF1-score = &quot; , confusion_matrix_scores_temp$f_score %&gt;% scales::percent(accuracy = 0.1) ) ) + theme_light() + theme( legend.position = &quot;none&quot; , panel.grid = element_blank() , plot.title = element_text(size = 9) , plot.subtitle = element_text(size = 9) ) that’s not very good as we could tell from the prediction map 3.4 Object-based image analysis (OBIA) OBIA is a technique (or a set of techniques) used to analyze digital images that was developed relatively recently in comparison to “classic” pixel-based image approaches (Burnett and Blaschke 2003). Goncalves et al. (2019) describe a general OBIA approach and created the SegOptim package to execute this framework. However, their package relies on 3rd party software to implement the initial image segmentation. The OTBsegm package is another package that relies on 3rd party software to implement image segmentation. Alternatively, imageseg is an R package for deep learning-based image segmentation (Niedballa et al. 2022). An alternative that does not require 3rd party software and works entirely within the R framework is the OpenImageR package. 3.4.1 Training data Training data is described as “typically a single-layer SpatRaster (from terra package) containing samples for training a classifier. The labels, classes or categories should be coded as integers {0,1} for single-class problems or, {1,2,…,n} for multi-class problems.” We just have a single-class problem of classification with two mutually exclusive levels: piles and non-piles. Other examples include: species presence/absence, burned/unburned, cut/uncut forest. first, we’ll make a raster covering the entire study area with cells classified based on the pile polygon locations class_rast &lt;- ortho_rast[[1]] %&gt;% # terra::subst(from = 0, to = NA) %&gt;% ## 0 values to NA which is specific to this data terra::clamp(lower=0,upper=0) %&gt;% terra::mask( slash_piles_polys %&gt;% # use ALL piles (image-annotated and field-collected) sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , inverse = T , updatevalue = 1 ) # terra::plot(class_rast) now we’ll make a grid of 0.25 ha to sample from to define our training versus validation areas. we’ll implement simple random sampling from this 0.25 ha grid. after we make the sample area, we’ll sample from our classfied raster # generates the grid sample_grid &lt;- ortho_rast[[1]] %&gt;% terra::clamp(lower=0,upper=0) %&gt;% terra::aggregate(fact = sqrt(10000*0.25)/terra::res(ortho_rast[[1]])[1]) # determins training tiles from the grid set.seed(66) sample_grid &lt;- terra::init(sample_grid, &quot;cell&quot;) %&gt;% terra::subst( from = sample(1:terra::ncell(sample_grid), size = floor(terra::ncell(sample_grid)*0.7)) , to = 1 , others = NA ) # terra::plot(sample_grid) # emmental # sample from the classified raster class_rast_training &lt;- class_rast %&gt;% terra::mask(terra::as.polygons(sample_grid)) check out the area we’ll use for training with the area for validation dimmed terra::plot(class_rast_training) terra::plot(class_rast, alpha = 0.2, add = T, axes=F, legend = F) 3.4.2 OpenImageR package SLIC image segmentation the OpenImageR package makes the Simple Linear Iterative Clustering (SLIC) clustering algorithm (Achanta et al. 2012) available in R. SLIC takes an image and segments it into “superpixels.” These superpixels are compact, nearly uniform regions that adhere well to image boundaries. The key idea is that within a superpixel, pixels are likely to belong to the same object or land cover type. This is a crucial first step because subsequent classification will be performed on these superpixels, not individual pixels. # the e1071 package is a popular choice for SVM implementation in R, providing a straightforward interface for training and evaluation. # remotes::install_github(&#39;mlampros/OpenImageR&#39;) # remotes::install_github(&#39;mlampros/SuperpixelImageSegmentation&#39;) library(&quot;OpenImageR&quot;) library(&quot;SuperpixelImageSegmentation&quot;) # list.files(system.file(&quot;tmp_images&quot;, package = &quot;OpenImageR&quot;)) # system.file(&quot;tmp_images&quot;, &quot;slic_im.png&quot;, package = &quot;OpenImageR&quot;) %&gt;% # terra::rast() %&gt;% # # terra::subset(1) %&gt;% # # terra::plot() # terra::plotRGB() #### save files to disk as required by package tempdir_temp &lt;- tempdir() fpath_train &lt;- file.path(tempdir_temp, &quot;train.tif&quot;) fpath_seg &lt;- file.path(tempdir_temp, &quot;seg.tif&quot;) fpath_class &lt;- file.path(tempdir_temp, &quot;class.tif&quot;) # write terra::writeRaster(class_rast_training, filename = fpath_train, overwrite = T) terra::writeRaster( pred_rast %&gt;% terra::subset(c(&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;)) , filename = fpath_seg , overwrite = T ) terra::writeRaster( pred_rast # includes indicies and textural as well as RGB , filename = fpath_class , overwrite = T ) we’ll implement the SLICO variation of SLIC because the user does not need to define the compactness parameter or try different values of it. SLICO adaptively chooses the compactness parameter for each superpixel differently. This generates regular shaped superpixels in both textured and non textured regions alike. The improvement comes with hardly any compromise on the computational efficiency - SLICO continues to be as fast as SLIC (How is SLICO different from SLIC?) #-------------- # &quot;slico&quot; method #-------------- # readImage on our RGB raster for segmentation im_temp &lt;- OpenImageR::readImage(fpath_seg) # str(im_temp) ## number of superpixels to use ## set this to extent/minimum expected pile area? sp_temp &lt;- floor( # raster area ( terra::cellSize(ortho_rast[[1]])[1]*terra::ncell(ortho_rast[[1]]) ) / # expected pile area ( slash_piles_polys %&gt;% dplyr::mutate(area = sf::st_area(.) %&gt;% as.numeric()) %&gt;% dplyr::pull(area) %&gt;% quantile(probs = 0.5) ) ) %&gt;% max(200) # 200 = function default # superpixels superpixels_slico_ans &lt;- OpenImageR::superpixels( input_image = im_temp # Either &quot;slic&quot; or &quot;slico&quot; , method = &quot;slico&quot; # number of superpixels to use , superpixel = sp_temp # numeric value specifying the compactness parameter. # The compactness parameter is needed only if method is &quot;slic&quot;. The &quot;slico&quot; method adaptively chooses # the compactness parameter for each superpixel differently # , compactness = 20 # If TRUE then the resulted slic or slico data will be returned , return_slic_data = TRUE # If TRUE then the Lab data will be returned ( the Lab-colour format ) , return_labels = TRUE # If not an empty string (&quot;&quot;) then it should be a path to the output file with extension .bin , write_slic = &quot;&quot; , verbose = TRUE ) ## The input image has the following dimensions: 2140 2731 3 ## The &#39;slico&#39; method will be utilized! ## The output image has the following dimensions: 2140 2731 3 what did we get back? str(superpixels_slico_ans) ## List of 2 ## $ slic_data: num [1:2140, 1:2731, 1:3] 0 0 0 0 0 0 0 0 0 0 ... ## $ labels : num [1:2140, 1:2731] 0 0 0 0 0 0 0 0 0 0 ... # superpixels_slico_ans$labels %&gt;% length() # superpixels_slico_ans$labels %&gt;% unique() %&gt;% length() # superpixels_slico_ans$labels %&gt;% dplyr::as_tibble() %&gt;% ncol() # superpixels_slico_ans$labels %&gt;% dplyr::as_tibble() %&gt;% nrow() # superpixels_slico_ans$slic_data %&gt;% str() let’s put the superpixels into a raster # use the ortho template so we get the projection and then fill with values superpixels_slico_rast &lt;- ortho_rast %&gt;% terra::subset(1) # fill raster with the superpixels superpixels_slico_rast[] &lt;- superpixels_slico_ans$labels %&gt;% terra::rast() superpixels_slico_rast &lt;- terra::as.factor(superpixels_slico_rast) # reset the colors terra::coltab(superpixels_slico_rast) &lt;- data.frame( value = terra::minmax(superpixels_slico_rast)[1]:terra::minmax(superpixels_slico_rast)[2] , col = c( viridis::turbo(terra::unique(superpixels_slico_rast) %&gt;% nrow() %&gt;% `*`(1/3) %&gt;% ceiling(), alpha = 0.35) , viridis::viridis(terra::unique(superpixels_slico_rast) %&gt;% nrow() %&gt;% `*`(1/3) %&gt;% ceiling(), alpha = 0.35) , viridis::cividis(terra::unique(superpixels_slico_rast) %&gt;% nrow() %&gt;% `*`(1/3) %&gt;% ceiling(), alpha = 0.35) ) %&gt;% sample(size = (terra::unique(superpixels_slico_rast) %&gt;% nrow())) ) # # plot # superpixels_slico_rast %&gt;% terra::plot(legend = F, axes = F) let’s look at the superpixels overlaid on the RGB image with the slash pile locations (blue) terra::plotRGB(ortho_rast, stretch = &quot;lin&quot;, colNA = &quot;black&quot;) terra::plot(superpixels_slico_rast, add = T, alpha = 0.2, border = &quot;white&quot;) # add polys terra::plot( slash_piles_polys %&gt;% sf::st_transform(terra::crs(ortho_rast)) %&gt;% terra::vect() , add = T, border = &quot;blue&quot;, col = NA ) # OpenImageR::NormalizeObject(superpixels_slico_ans$slic_data) %&gt;% # grDevices::as.raster() %&gt;% # graphics::plot() that’s neat, the superpixels are moderately aligned with the large machine piles but are generally too large for the smaller hand piles the steps in the OBIA approach workflow described by Goncalves et al. (2019) would be: Image Segmentation (e.g. using SLIC) as demonstrated above Feature Extraction for Superpixels: instead of using individual pixel values, extract features that describe each superpixel (e.g. spectral bands, band ratios, textural features) Use labeled training data to assign superpixels to their respective classes and perform classifier training (i.e. using random forest, support vector machines, etc.) Once the classifier is trained, you apply it to the features of all the unlabeled superpixels in the image 3.4.2.1 Feature Extraction for Superpixels let’s classify the superpixels we generated using SLICO Image Segmentation (e.g. using SLIC) as demonstrated above Feature Extraction for Superpixels: instead of using individual pixel values, extract features that describe each superpixel (e.g. spectral bands, band ratios, textural features) Use labeled training data to assign superpixels to their respective classes and perform classifier training (i.e. using random forest, support vector machines, etc.) Once the classifier is trained, you apply it to the features of all the unlabeled superpixels in the image # terra::plot(superpixels_slico_rast, legend = F) # terra::values(superpixels_slico_rast) %&gt;% unique() %&gt;% length() # terra::as.polygons(superpixels_slico_rast, aggregate = T, values = T) %&gt;% terra::plot(legend = T) # convert superpixels to polygons superpixels_slico_sf &lt;- terra::as.polygons(superpixels_slico_rast, aggregate = T, values = T) %&gt;% sf::st_as_sf() %&gt;% dplyr::rename(superpixel_id = 1) # list of functions to aggregate pixel data to superpixel fn_list &lt;- list( mean = function(x){mean(x,na.rm = T)} , median = function(x){median(x,na.rm = T)} , sd = function(x){sd(x,na.rm = T)} , q90 = function(x){quantile(x, probs = 0.9, na.rm = T)} , q10 = function(x){quantile(x, probs = 0.1, na.rm = T)} # , mode = function(x) { # # Get the unique values in the vector # unique_values &lt;- unique(x) # # Calculate the frequency of each unique value # value_frequencies &lt;- tabulate(match(x, unique_values)) # # Find the index of the maximum frequency # max_frequency_index &lt;- which.max(value_frequencies)[1] # # Return the unique value corresponding to the maximum frequency # return(unique_values[max_frequency_index]) # } ) # feature extraction for superpixels and aggregation superpixels_features_df &lt;- pred_rast %&gt;% terra::extract( y = superpixels_slico_sf %&gt;% terra::vect() , ID = T ) %&gt;% dplyr::group_by(ID) %&gt;% dplyr::summarise(dplyr::across( .cols = dplyr::where(is.numeric) , .fns = fn_list , .names = &quot;{.col}_{.fn}&quot; )) %&gt;% dplyr::ungroup() %&gt;% # get rid of summary variables for local_minima values since it&#39;s on 0-8 scale dplyr::select( -c( tidyselect::contains(&quot;local_minima_mean&quot;) , tidyselect::contains(&quot;local_minima_median&quot;) , tidyselect::contains(&quot;local_minima_sd&quot;) , tidyselect::contains(&quot;local_minima_q10&quot;) , tidyselect::contains(&quot;local_minima_q90&quot;) , tidyselect::contains(&quot;local_minima&quot;) # just get rid of all local_minima since aggregation at this level just results in 0&#39;s ) ) %&gt;% # get rid of nan dplyr::mutate(dplyr::across( .cols = dplyr::where(is.numeric) , .fns = ~ ifelse( is.nan(.x) | is.infinite(.x) , as.numeric(NA) , .x ) )) # add to the spatial data superpixels_slico_sf &lt;- superpixels_slico_sf %&gt;% dplyr::bind_cols(superpixels_features_df %&gt;% dplyr::select(-ID)) let’s check out that we got what we expected by plotting median GRVI in each superpixel superpixels_slico_sf %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill = grvi_median)) + harrypotter::scale_fill_hp(option = &quot;slytherin&quot;, na.value = &quot;black&quot;) + ggplot2::theme_void() + ggplot2::theme(legend.position = &quot;none&quot;) # grvi_rast %&gt;% terra::aggregate(fact = 4) %&gt;% # terra::plot(axes = F, legend = F, col = harrypotter::hp(n=200, option = &quot;slytherin&quot;)) looks good. now we’ll use the training data to attach pile/non-pile information to each superpixel check the training versus validation (dimmed) data with the superpixels overlaid terra::plot(class_rast_training, axes=F, legend = F) terra::plot(class_rast, alpha = 0.2, add = T, axes=F, legend = F) superpixels_slico_sf %&gt;% terra::vect() %&gt;% terra::plot(add = T) we’ll take the mean of the 0/1 values to get the proportion of the superpixel that overlaps with the location of a pile (think of this as the probability that a superpixel is a pile) # get rid of superpixels that are in the validation training_superpixel_id &lt;- terra::mask( superpixels_slico_sf %&gt;% terra::vect() , sample_grid %&gt;% terra::as.polygons() ) %&gt;% sf::st_as_sf() %&gt;% sf::st_drop_geometry() %&gt;% dplyr::pull(superpixel_id) # extract classified values training_df &lt;- class_rast %&gt;% terra::extract( y = superpixels_slico_sf %&gt;% dplyr::filter(superpixel_id %in% training_superpixel_id) %&gt;% terra::vect() , fun = &quot;mean&quot; , ID = T , na.rm = T ) %&gt;% dplyr::rename(pr_pile = 2) %&gt;% # get rid of nan dplyr::mutate(dplyr::across( .cols = dplyr::where(is.numeric) , .fns = ~ ifelse( is.nan(.x) | is.infinite(.x) , as.numeric(NA) , .x ) )) # join with features and pile id&#39;s, geometry training_df &lt;- superpixels_slico_sf %&gt;% dplyr::filter(superpixel_id %in% training_superpixel_id) %&gt;% dplyr::bind_cols(training_df %&gt;% dplyr::select(-ID)) %&gt;% dplyr::filter(!is.na(pr_pile)) %&gt;% # because all values should be filled except for validation data dplyr::filter(!dplyr::if_any(dplyr::everything(), ~ is.na(.x))) # cant pass NA to classifier # what? training_df %&gt;% dplyr::glimpse() ## Rows: 21,409 ## Columns: 43 ## $ superpixel_id &lt;chr&gt; &quot;42&quot;, &quot;43&quot;, &quot;44&quot;, &quot;45&quot;, &quot;46&quot;, &quot;47&quot;, &quot;48&quot;,… ## $ red_mean &lt;dbl&gt; 1.5731712, 2.8678193, 4.6008164, 1.353911… ## $ red_median &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ red_sd &lt;dbl&gt; 6.1131305, 10.7871888, 17.3409717, 8.9573… ## $ red_q90 &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0… ## $ red_q10 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ green_mean &lt;dbl&gt; 1.5541302, 2.8061940, 4.0646794, 1.302036… ## $ green_median &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ green_sd &lt;dbl&gt; 6.0804750, 10.5539217, 15.3166787, 8.6065… ## $ green_q90 &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0… ## $ green_q10 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ blue_mean &lt;dbl&gt; 1.5557635, 2.7709314, 3.7550514, 1.339822… ## $ blue_median &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ blue_sd &lt;dbl&gt; 6.0809556, 10.4269112, 14.1666451, 8.8711… ## $ blue_q90 &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0… ## $ blue_q10 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ panchromatic_local_sd_mean &lt;dbl&gt; 346.7146, 289.2376, 247.9397, 317.5551, 3… ## $ panchromatic_local_sd_median &lt;dbl&gt; 337.9099, 286.6318, 245.6666, 329.2800, 3… ## $ panchromatic_local_sd_sd &lt;dbl&gt; 27.61192, 23.55341, 20.06296, 26.18637, 2… ## $ panchromatic_local_sd_q90 &lt;dbl&gt; 385.9283, 322.3833, 273.9702, 347.3282, 3… ## $ panchromatic_local_sd_q10 &lt;dbl&gt; 312.20620, 257.49864, 220.90196, 286.5811… ## $ panchromatic_local_cv_mean &lt;dbl&gt; 3.171530, 2.526854, 2.087962, 4.153971, 4… ## $ panchromatic_local_cv_median &lt;dbl&gt; 3.160974, 2.514665, 2.071667, 4.223150, 4… ## $ panchromatic_local_cv_sd &lt;dbl&gt; 0.2179736, 0.1679546, 0.1912705, 0.281994… ## $ panchromatic_local_cv_q90 &lt;dbl&gt; 3.519176, 2.727496, 2.327892, 4.448096, 4… ## $ panchromatic_local_cv_q10 &lt;dbl&gt; 2.924997, 2.303509, 1.861655, 3.798575, 3… ## $ grvi_mean &lt;dbl&gt; -0.009289024, -0.010754824, -0.061775662,… ## $ grvi_median &lt;dbl&gt; -0.017701689, -0.014837562, -0.061749834,… ## $ grvi_sd &lt;dbl&gt; 0.018805043, 0.025992220, 0.008282992, 0.… ## $ grvi_q90 &lt;dbl&gt; 0.018994675, 0.021895162, -0.052431733, 0… ## $ grvi_q10 &lt;dbl&gt; -0.024501407, -0.037844312, -0.072411286,… ## $ grvi_local_sd_mean &lt;dbl&gt; 0.07714129, 0.09509241, 0.08269488, 0.128… ## $ grvi_local_sd_median &lt;dbl&gt; 0.07851025, 0.09002175, 0.07821382, 0.121… ## $ grvi_local_sd_sd &lt;dbl&gt; 0.021432447, 0.015912938, 0.018352081, 0.… ## $ grvi_local_sd_q90 &lt;dbl&gt; 0.10187750, 0.12002765, 0.10791821, 0.161… ## $ grvi_local_sd_q10 &lt;dbl&gt; 0.05166833, 0.07801328, 0.06245443, 0.108… ## $ grvi_local_cv_mean &lt;dbl&gt; 0.33581224, 0.64111396, 0.00000000, 0.032… ## $ grvi_local_cv_median &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0… ## $ grvi_local_cv_sd &lt;dbl&gt; 0.6315997, 0.9322054, 0.0000000, 0.179605… ## $ grvi_local_cv_q90 &lt;dbl&gt; 1.131318, 2.000000, 0.000000, 0.000000, 0… ## $ grvi_local_cv_q10 &lt;dbl&gt; 0.000000, 0.000000, 0.000000, 0.000000, 0… ## $ pr_pile &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ geometry &lt;POLYGON [m]&gt; POLYGON ((499421.5 4318139,..., P… for superpixels covered by a pile, what is the distribution of percentage of superpixel that is covered by a pile? training_df %&gt;% dplyr::filter(pr_pile&gt;0) %&gt;% dplyr::pull(pr_pile) %&gt;% summary() ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.00361 0.06102 0.20118 0.32461 0.52263 1.00000 check it on the map training_df %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill = pr_pile)) + ggplot2::geom_sf(data = slash_piles_polys, fill = NA, color = &quot;blue&quot;, lwd = 0.3) + ggplot2::scale_fill_viridis_c(option = &quot;mako&quot;, direction = -1, na.value = &quot;white&quot;) + ggplot2::theme_void() we can also see what it looks like if we include only pixels with &gt;20% (~median value) of their area covered by a pile training_df %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill = pr_pile&gt;0.2)) + ggplot2::geom_sf(data = slash_piles_polys, fill = NA, color = &quot;blue&quot;, lwd = 0.3) + ggplot2::scale_fill_viridis_d(option = &quot;magma&quot;, begin = 0.2, end = 0.8, na.value = &quot;white&quot;) + ggplot2::theme_void() 3.4.2.2 Classifier training for Superpixels nice, now let’s train the a random forest classifier to predict superpixel values # Tune on the full data if below threshold tune_result_temp &lt;- randomForest::tuneRF( y = training_df$pr_pile , x = training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(superpixel_id,pr_pile)) , ntreeTry = 500 , stepFactor = 1 , improve = 0.03 , plot = F , trace = F ) # Extract the optimal mtry value optimal_mtry_temp &lt;- tune_result_temp %&gt;% dplyr::as_tibble() %&gt;% dplyr::filter(OOBError==min(OOBError)) %&gt;% dplyr::filter(dplyr::row_number() == 1) %&gt;% dplyr::pull(mtry) %&gt;% as.numeric() # pass to random forest model mod_rf &lt;- randomForest::randomForest( y = training_df$pr_pile , x = training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(superpixel_id,pr_pile)) , mtry = optimal_mtry_temp , na.action = na.omit , ntree = 500 ) random forest variable importance plot #variable importance plot randomForest::varImpPlot(mod_rf) 3.4.2.3 Predict values for validation superpixels validation_df &lt;- superpixels_slico_sf %&gt;% dplyr::filter(!superpixel_id %in% training_superpixel_id) %&gt;% dplyr::filter(!dplyr::if_any(dplyr::everything(), ~ is.na(.x))) # cant pass NA to classifier # predict validation_df &lt;- validation_df %&gt;% dplyr::mutate( pr_pile_pred = stats::predict( mod_rf , newdata = validation_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select( training_df %&gt;% sf::st_drop_geometry() %&gt;% dplyr::select(-c(superpixel_id,pr_pile)) %&gt;% names() ) ) ) plot predictions validation_df %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill = pr_pile_pred)) + ggplot2::geom_sf(data = slash_piles_polys, fill = NA, color = &quot;blue&quot;, lwd = 0.3) + ggplot2::scale_fill_viridis_c(option = &quot;mako&quot;, direction = -1, na.value = &quot;white&quot;) + ggplot2::theme_void() we can also see what it looks like if we include only pixels with &gt;10% of their area covered by a pile validation_df %&gt;% ggplot2::ggplot() + ggplot2::geom_sf(ggplot2::aes(fill = pr_pile_pred&gt;0.2)) + ggplot2::geom_sf(data = slash_piles_polys, fill = NA, color = &quot;blue&quot;, lwd = 0.3) + ggplot2::scale_fill_viridis_d(option = &quot;magma&quot;, begin = 0.2, end = 0.8, na.value = &quot;white&quot;) + ggplot2::theme_void() evaluate model performance based on the Area under the Receiver Operating Characteristic (ROC) Curve (AUC) criterion (an AUC value of 0.5 can be interpreted as the model performing no better than a random prediction). Higher AUC values indicate that the model is better at predicting “absence” classes as “absence” (true negative) and “presence” classes as “presence” (true positive). ### coming soon "],["point-cloud-classification.html", "Section 4 Point Cloud Classification 4.1 Process Raw Point Cloud", " Section 4 Point Cloud Classification We’ll use the point cloud data alone (to begin with) to attempt to classify slash piles without additional spectral information. We’ll use the cloud2trees package to perform all preprocessing of point cloud data which includes: ground classification and noise removal raster data (DTM and CHM) generation point cloud height normalization All of this can be accomplished using the cloud2raster() function. After generating these products from the raw point cloud we’ll perform object segmentation to attempt to detect round, conical objects like slash piles from: 1) the normalized point cloud directly; 2) the CHM which we’ll generate by setting the minimum height to zero to effectively create a digital surface model (DSM). To attempt to detect slash piles directly from the point cloud we can use a clustering algorithm such as DBSCAN (Density-Based Spatial Clustering of Applications with Noise) which identifies clusters based on point density, making it effective for detecting clusters of arbitrary shapes and sizes. It does not require the number of clusters to be specified beforehand. Insert something from TLS paper that used DBSCAN in semi-automated way….xxxxx. After segmenting the point cloud using DBSCAN, random forest can be used as a classifier (i.e. classification step) to distinguish slash piles from other objects based on their extracted geometric features. The general workflow is: for each point in the normalized non-ground point cloud, compute a suite of relevant geometric features within a defined local neighborhood radius using lidR::point_metrics() calculate features derived from PCA, such as linearity, planarity, sphericity, and surface variation. Also, compute curvature (mean, Gaussian) and roughness perform object segmentation/clustering to group points belonging to individual objects using DBSCAN which can identify dense clusters without requiring a predefined number of objects classify the segmented objects (clusters) as “slash pile” or “non-slash pile” based on their extracted features (e.g., sphericity, roughness, height, volume) with a random forest classifier using a manually annotated subset of segmented objects merge small, adjacent segments that likely belong to a single slash pile based on proximity and connectivity perform a confusion matrix-based evaluation on the results To attempt to identify slash piles from the CHM/DSM, we can use watershed segmentation (potentially without “seed” points) in a bottom-up approach. Insert something from paper about bottom-up approach that uses a CHM “slice” near the ground…xxxxx. For slash piles, which are often irregular and may not have a distinct “treetop” equivalent, CHM-based methods might be less directly applicable unless the piles present a very clear, isolated conical or rounded form. Could use expected morphology of the slash piles (e.g. maximum height) based on prior research. 4.1 Process Raw Point Cloud We’ll use cloud2trees::cloud2raster() to process the raw point cloud data if(!dir.exists(&quot;../data/point_cloud_processing_delivery&quot;)){ cloud2raster_ans &lt;- cloud2trees::cloud2raster( output_dir = &quot;../data&quot; , input_las_dir = &quot;D:\\\\PFDP_Data\\\\p4pro_images\\\\P4Pro_06_17_2021_half_half_optimal\\\\2_densification\\\\point_cloud&quot; , max_ctg_pts = 9e+07 , accuracy_level = 3 , keep_intrmdt = T , dtm_res_m = 0.5 , chm_res_m = 0.2 , min_height = 0 # effectively generates a DSM based on non-ground points ) }else{ dtm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery/dtm_0.5m.tif&quot;) chm_temp &lt;- terra::rast(&quot;../data/point_cloud_processing_delivery/chm_0.2m.tif&quot;) cloud2raster_ans &lt;- list( &quot;dtm_rast&quot; = dtm_temp , &quot;chm_rast&quot; = chm_temp ) } let’s check out the DTM and CHM "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
